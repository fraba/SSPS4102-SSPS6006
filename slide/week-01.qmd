---
title: "Week 01</br>Introduction and Overview"
subtitle: "SSPS4102 Data Analytics in the Social Sciences<br>SSPS6006 Data Analytics for Social Research<br><br><br>Semester 1, 2026<br>Last updated: `r Sys.Date()`"
author: "Francesco Bailo"
format:
  revealjs:
    self-contained: true
    fig-format: retina
    toc: true
    toc-depth: 1
    toc-title: "In this lecture"
    theme: [default, "assets/sydney.scss"]
    code-line-numbers: false
    slide-number: c
    scrollable: false
    pdf-max-pages-per-slide: 1
    history: false
bibliography: assets/pres_bib.bib
csl: assets/apa-old-doi-prefix.csl
execute:
  echo: true
---

## Acknowledgement of Country

I would like to acknowledge the Traditional Owners of Australia and recognise their continuing connection to land, water and culture. The University of Sydney is located on the land of the Gadigal people of the Eora Nation. I pay my respects to their Elders, past and present.

---

```{r}
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
```

# What is Data Science?

## Learning objectives

By the end of this lecture, you will be able to:

1. Understand the role of data analysis in social science research
2. Explain the three fundamental challenges of statistics
3. Describe the Plan-Simulate-Acquire-Explore-Share workflow
4. Understand data validity and reliability
5. Set up R and RStudio environment

::: notes
These are the key learning objectives for Week 1. We'll build on these throughout the semester.
:::

## What is data science?

::: callout-note
### A working definition

**Data science** is *humans measuring things, typically related to other humans, and using sophisticated averaging to explain and predict*.
:::

. . .

This definition emphasises:

- Data are generated by **humans** and about **humans**
- The process of turning the world into data involves many **decisions**
- Analysis involves explanation *and* prediction

::: aside
Definition adapted from Alexander (2023), *Telling Stories with Data*
:::

## Data science in social research

Data science allows us to:

1. **Predict** outcomes (elections, behaviour, health)
2. **Explore associations** (risk factors, attitudes, characteristics)
3. **Extrapolate** from samples to populations
4. **Make causal inferences** about treatments and interventions

. . .

> "In any case the key elements are the same... What is the dataset? Who generated it and why? What is missing?"

::: notes
These four uses of data science map directly onto regression analysis, which we'll cover later in the semester.
:::

## The challenge of measurement

::: columns
::: {.column width="50%"}
Even seemingly simple things are hard to measure:

- **Height**: Changes during the day; tape vs laser gives different results
- **Happiness**: How do we quantify subjective feelings?
- **Income**: Before or after tax? Per person or household?
:::

::: {.column width="50%"}
![Picasso's single-line dog drawing](https://upload.wikimedia.org/wikipedia/en/9/93/Pablo_Picasso%2C_1907%2C_Les_Demoiselles_d%27Avignon%2C_oil_on_canvas%2C_243.9_x_233.7_cm%2C_Museum_of_Modern_Art.jpg){width="80%" fig-alt="Illustration of simplified representation"}

*What is the minimum we need to capture the essence?*
:::
:::

::: notes
The Picasso drawing example from TSwD shows how we can recognise something from minimal information - but is that enough for our analytical purposes?
:::

# The Three Challenges of Statistics

## The three challenges

::: callout-important
### Fundamental challenges of statistical inference

1. **Generalising from sample to population**
2. **Generalising from treatment to control group**
3. **Generalising from observed measurements to underlying constructs**
:::

These challenges arise in nearly every application of data analysis!

::: aside
From Gelman, Hill & Vehtari (2021), *Regression and Other Stories*
:::

## Challenge 1: Sample to population

**The problem**: We usually only observe a *sample* of the population we care about.

::: columns
::: {.column width="50%"}
**Examples**:

- Surveys don't reach everyone
- Not everyone responds
- Some groups are harder to reach
:::

::: {.column width="50%"}
**Selection bias**: The people we observe may differ systematically from those we don't.

*Who is systematically missing from our data?*
:::
:::

::: notes
The Xbox polling example from ROS Chapter 1 shows how even 750,000 responses can be biased if they're not representative.
:::

## Challenge 2: Treatment to control

**The problem**: We want to know what would have happened *if* we had made a different choice.

::: columns
::: {.column width="50%"}
**In experiments**:

- Randomly assign treatment
- Compare outcomes
- Estimate causal effect
:::

::: {.column width="50%"}
**In observational studies**:

- Treatment is *not* randomly assigned
- Groups may differ before treatment
- Must adjust for differences
:::
:::

. . .

::: callout-warning
### Correlation ≠ Causation

Just because two things are associated doesn't mean one causes the other!
:::

## Challenge 3: Measurement to constructs

**The problem**: What we *measure* is rarely what we actually *want to know*.

::: {layout-ncol="2"}
### What we measure

- Survey responses
- Test scores
- Administrative records
- Social media posts

### What we want to know

- True opinions
- Actual ability
- Real behaviour
- Population sentiment
:::

. . .

> "Most of the time our data do not record exactly what we would ideally like to study."

## Example: The Human Development Index

::: columns
::: {.column width="60%"}
The HDI claims to measure "human development" using:

- Life expectancy
- Education (literacy + enrolment)
- Standard of living (GDP per capita)

**But**: Most variation between US states comes from *income*, not health or education!
:::

::: {.column width="40%"}
The lesson: **Always examine where your numbers come from.**

*What does your measure actually capture?*
:::
:::

::: aside
Example from Gelman, Hill & Vehtari (2021), Chapter 2
:::

::: notes
The HDI example shows how a composite measure can obscure what's really driving differences.
:::

# Data Quality: Validity and Reliability

## Validity

::: callout-note
### Definition

A measure is **valid** to the degree that it represents what you are trying to measure.
:::

**Examples of validity problems**:

- A written test as a measure of musical ability ❌
- Customer satisfaction surveys as a measure of service effectiveness ❓
- Blood pressure readings as a measure of cardiovascular health ✓

. . .

**Key question**: Is there general agreement that the observations are closely related to the intended construct?

## Reliability

::: callout-note
### Definition

A **reliable** measure is one that is precise and stable—if we measure again, we get similar values.
:::

**Ways to assess reliability**:

- **Test-retest**: Give the same test twice
- **Inter-rater**: Have different people make the same measurement
- **Internal consistency**: Do related items give similar results?

. . .

::: callout-tip
### The key insight

Variability in our data should reflect *real differences*, not measurement error.
:::

## Validity vs reliability

::: {layout-ncol="2"}
### High validity, low reliability

- Measuring the right thing
- But inconsistently
- *Example*: Accurate but shaky scale

### High reliability, low validity

- Consistent measurements
- But of the wrong thing
- *Example*: Precisely measuring height when you want to know weight
:::

. . .

::: callout-important
### We need both!

A measure can be reliable without being valid, but a valid measure must be reasonably reliable.
:::

## All graphs are comparisons

When exploring data, remember:

> "All graphical displays can be considered as comparisons."

**Effective graphs**:

- Line things up so important comparisons are clear
- Use appropriate scales
- Show what the model is doing
- Highlight unexpected patterns

::: notes
This is a key principle from ROS Chapter 2 that we'll use throughout the course.
:::

# The Data Science Workflow

## The five-step workflow

::: callout-important
### Plan → Simulate → Acquire → Explore → Share
:::

```{r}
#| echo: false
#| fig-width: 10
#| fig-height: 3
workflow_data <- tibble(
  step = factor(c("Plan", "Simulate", "Acquire", "Explore", "Share"), 
                levels = c("Plan", "Simulate", "Acquire", "Explore", "Share")),
  x = 1:5,
  y = 1
)

ggplot(workflow_data, aes(x = x, y = y)) +
  geom_point(size = 15, colour = "#00539b") +
  geom_text(aes(label = step), colour = "white", fontface = "bold", size = 4) +
  geom_segment(aes(x = x + 0.3, xend = x + 0.7, y = y, yend = y),
               data = workflow_data |> filter(x < 5),
               arrow = arrow(length = unit(0.3, "cm")),
               colour = "#00539b", linewidth = 1) +
  theme_void() +
  coord_cartesian(xlim = c(0.5, 5.5))
```

This workflow guides everything we do in this course.

::: aside
From Alexander (2023), *Telling Stories with Data*
:::

## Step 1: Plan

**Why plan first?**

> "In Alice's Adventures in Wonderland, Alice asks the Cheshire Cat which way she should go. The Cat replies that it depends on where Alice wants to get to."

. . .

Planning involves:

- Sketching the **endpoint** (what graph/table do you want?)
- Identifying the **data** you need
- Considering **who is affected** by your analysis

::: callout-tip
### Practical tip
Ten minutes with paper and pen is often enough to get started!
:::

## Step 2: Simulate

**Why simulate data?**

::: columns
::: {.column width="50%"}
**For data cleaning**:

- Forces you to think about data types
- Helps define expected values
- Creates tests for your real data
:::

::: {.column width="50%"}
**For modelling**:

- Know the "truth" in advance
- Test if your model recovers it
- Build confidence before real data
:::
:::

. . .

> "Simulation is often cheap—almost free given modern computing resources—and fast."

## Step 3: Acquire

**Data acquisition is often overlooked but critical!**

Key considerations:

- Where does the data come from?
- Who collected it and why?
- What's missing or poorly measured?
- What decisions have already been made?

. . .

::: callout-warning
### Data never "speak for themselves"

They are shaped by the choices of those who collected and prepared them.
:::

## Step 4: Explore

**Exploratory Data Analysis (EDA)** involves:

- Summary statistics
- Graphs and tables
- Initial modelling
- Understanding the "shape" of your data

. . .

This is an **iterative** process that continues throughout your project.

> "It is difficult to delineate where EDA ends and formal statistical modelling begins."

## Step 5: Share

::: callout-important
### Communication is the most important element

Simple analysis, communicated well, is more valuable than complicated analysis communicated poorly.
:::

**Clear communication means**:

- Writing in plain language
- Using appropriate tables and graphs
- Explaining decisions and limitations
- Making your work **reproducible**

## Key elements of telling stories with data

1. **Communication** — Clear, audience-focused writing
2. **Reproducibility** — Others can redo your work
3. **Ethics** — Considering who is affected
4. **Questions** — Curiosity drives good research
5. **Measurement** — Understanding what data capture

::: notes
These five elements underpin everything we'll do in the course.
:::

# Getting Started with R

## Why R?

::: columns
::: {.column width="50%"}
**Advantages**:

- Free and open source
- Huge community
- Excellent for statistics
- Great visualisation
- Reproducible documents
:::

::: {.column width="50%"}
**For this course**:

- Standard in social science
- Well-documented
- Active package development
- Integrates with Quarto
:::
:::

::: aside
See Appendix A in Gelman, Hill & Vehtari (2021) for more on R setup.
:::

## Setting up: Posit Cloud

For beginners, we recommend starting with **Posit Cloud**:

1. Go to [posit.cloud](https://posit.cloud)
2. Create a free account
3. Start a new RStudio Project

. . .

::: callout-tip
### Why Posit Cloud?

- No installation required
- Same experience for everyone
- Easy to share code
- Free tier is sufficient for learning
:::

::: notes
Later in the semester, students can transition to local R installation if they prefer.
:::

## The RStudio interface

::: columns
::: {.column width="50%"}
**Four main panes**:

1. **Source** — Write and edit code
2. **Console** — Run commands
3. **Environment** — View objects
4. **Files/Plots/Help** — Navigate and view outputs
:::

::: {.column width="50%"}
**Key shortcuts**:

- `Ctrl/Cmd + Enter` — Run current line
- `Ctrl/Cmd + Shift + Enter` — Run chunk
- `Tab` — Autocomplete
- `Ctrl/Cmd + S` — Save
:::
:::

## Your first R commands

```{r}
# This is a comment - R ignores it
# Basic arithmetic
1 + 1
```

. . .

```{r}
# Creating objects with the assignment operator
my_number <- 42
my_number
```

. . .

```{r}
# Using functions
sqrt(my_number)
```

## Installing and loading packages

**Packages** extend R's functionality.

```{r}
#| eval: false
# Install a package (only need to do once)
install.packages("tidyverse")

# Load a package (need to do each session)
library(tidyverse)
```

. . .

::: callout-note
### Key packages for this course

- **tidyverse**: Data manipulation and visualisation
- **janitor**: Data cleaning utilities
- **knitr**: Document generation
:::

## Creating a Quarto document

**Quarto** combines text and code for reproducible research.

1. File → New File → Quarto Document
2. Add a title and your name
3. Click "Create"

. . .

Key elements:

- **YAML header** — Document settings
- **Markdown** — Formatted text
- **Code chunks** — Executable R code

## Code chunks

Code chunks contain R code that will be executed:

````{verbatim}
```{r}
# Your R code goes here
mean(c(1, 2, 3, 4, 5))
```
````

. . .

Produces:

```{r}
mean(c(1, 2, 3, 4, 5))
```

## Chunk options

Control how chunks behave:

````{verbatim}
```{r}
#| echo: false    # Don't show the code
#| eval: true     # Do run the code
#| message: false # Hide messages
#| warning: false # Hide warnings
```
````

::: notes
We'll use these throughout the course to control what appears in our documents.
:::

# Worked Example: Australian Elections

## Putting it all together

Let's walk through the complete workflow with a real example:

**Question**: How many seats did each party win in the 2022 Australian Federal Election?

. . .

::: callout-tip
### The workflow

1. **Plan**: Sketch the data and graph we need
2. **Simulate**: Create fake data to test our approach
3. **Acquire**: Get the real data
4. **Explore**: Analyse and visualise
5. **Share**: Communicate our findings
:::

## Step 1: Plan

::: columns
::: {.column width="50%"}
**Data we need**:

| Division | Party |
|----------|-------|
| Adelaide | Labor |
| Aston | Liberal |
| ... | ... |
:::

::: {.column width="50%"}
**Graph we want**:

A bar chart showing the number of seats won by each party.
:::
:::

::: notes
In practice, you'd sketch these by hand on paper.
:::

## Step 2: Simulate

```{r}
# Create simulated data
simulated_data <- tibble(
  division = 1:151,  # 151 seats in the House
  party = sample(
    x = c("Liberal", "Labor", "Nationals", "Greens", "Other"),
    size = 151,
    replace = TRUE
  )
)

# Check the first few rows
head(simulated_data)
```

## Step 3: Acquire

```{r}
#| eval: false
# Read data from the Australian Electoral Commission
raw_elections_data <- read_csv(
  file = paste0(
    "https://results.aec.gov.au/27966/website/Downloads/",
    "HouseMembersElectedDownload-27966.csv"
  ),
  skip = 1
)
```

```{r}
#| echo: false
# For the slides, we'll simulate the cleaned data
cleaned_elections_data <- tibble(
  division = c("Adelaide", "Aston", "Ballarat", "Banks", "Barker", "Barton",
               "Bass", "Bean", "Bendigo", "Bennelong"),
  elected_party = c("Labor", "Liberal", "Labor", "Liberal", "Liberal", 
                    "Labor", "Labor", "Labor", "Labor", "Liberal")
)

# Simulate full dataset for the plot
set.seed(2022)
full_data <- tibble(
  division = paste0("Division_", 1:151),
  elected_party = sample(
    c(rep("Labor", 77), rep("Liberal", 48), rep("Nationals", 10),
      rep("Greens", 4), rep("Other", 12))
  )
)
```

## Step 4: Explore — Counting seats

```{r}
# Count seats by party
full_data |>
  count(elected_party) |>
  arrange(desc(n))
```

## Step 4: Explore — Creating a graph

```{r}
#| fig-width: 10
#| fig-height: 5
full_data |>
  ggplot(aes(x = elected_party)) +
  geom_bar(fill = "#00539b") +
  theme_minimal(base_size = 16) +
  labs(
    x = "Party",
    y = "Number of seats",
    title = "2022 Australian Federal Election Results"
  )
```

## Step 5: Share

> Australia is a parliamentary democracy with 151 seats in the House of Representatives. The 2022 Federal Election saw the Labor Party win 77 seats, followed by the Liberal Party with 48 seats.

**Key findings**:

- Labor won a majority (77 seats)
- The two major parties dominate
- Minor parties and independents won 26 seats combined

::: notes
This is a simplified version of what a full write-up would look like.
:::

# Wrap-up

## This week's readings

::: columns
::: {.column width="50%"}
**Telling Stories with Data**:

- Ch 1: Telling stories with data
- Ch 2: Drinking from a fire hose (§2.1-2.2)
:::

::: {.column width="50%"}
**Regression and Other Stories**:

- Ch 1: Overview
- Ch 2: Data and Measurement
:::
:::

::: callout-tip
### Reading strategy

Focus on the *concepts* first. The technical details will make more sense as we practise.
:::

## Key takeaways

1. **Data science** is about humans measuring things to explain and predict
2. The **three challenges** of statistics pervade all analysis
3. **Validity** and **reliability** are fundamental to good measurement
4. The **Plan-Simulate-Acquire-Explore-Share** workflow guides our work
5. **R** is a powerful tool for reproducible data analysis

## Next week

**Week 2: Reproducible Workflows and Version Control**

- Creating reproducible documents with Quarto
- Organising projects with R Projects
- Introduction to Git and GitHub

::: callout-important
### Before next week

- Set up your Posit Cloud account
- Work through the Australian elections example
- Complete the readings
:::

## Questions?

::: columns
::: {.column width="50%"}
**Office hours**:

- TBA

**Email**:

- francesco.bailo@sydney.edu.au
:::

::: {.column width="50%"}
**Resources**:

- Course Canvas site
- Textbook websites
- R documentation
:::
:::

## References
