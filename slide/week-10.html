<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>SSPS [4102|6006] Data Analytics[in the Social Sciences|for Social Research]</title>
    <meta charset="utf-8" />
    <meta name="author" content="Francesco Bailo" />
    <script src="week-10_files/header-attrs/header-attrs.js"></script>
    <link href="week-10_files/remark-css/default.css" rel="stylesheet" />
    <link href="week-10_files/htmltools-fill/fill.css" rel="stylesheet" />
    <script src="week-10_files/htmlwidgets/htmlwidgets.js"></script>
    <script src="week-10_files/viz/viz.js"></script>
    <link href="week-10_files/DiagrammeR-styles/styles.css" rel="stylesheet" />
    <script src="week-10_files/grViz-binding/grViz.js"></script>
    <link href="week-10_files/countdown/countdown.css" rel="stylesheet" />
    <script src="week-10_files/countdown/countdown.js"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        TeX: { equationNumbers: { autoNumber: "AMS" } },
      });
    </script>
    <style>
    .mjx-mrow a {
      color: black;
      pointer-events: none;
      cursor: default;
    }
    </style>
    <link rel="stylesheet" href="assets/sydney-fonts.css" type="text/css" />
    <link rel="stylesheet" href="assets/sydney.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# SSPS [4102|6006] Data Analytics</br>[in the Social Sciences|for Social Research]
]
.subtitle[
## Week 10</br>Textual Data: Natural Language Features
]
.author[
### Francesco Bailo
]
.date[
### Semester 2, 2024 (updated: 2024-10-11)
]

---


background-image: url('assets/USydLogo.svg')
background-size: 95%

&lt;style&gt;
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
&lt;/style&gt;



---

## Acknowledgement of Country

I would like to acknowledge the Traditional Owners of Australia and recognise their continuing connection to land, water and culture. The  University of Sydney is located on the land of the Gadigal people  of the Eora Nation. I pay my respects to their Elders, past and present.
---

## Recap from last week

- Machine learning
- K-nearest neighbors algorithm (k-NN) classification (2+ classes)
- Linear regression (again!) for numeric prediction
- Logistic regression for binary classification (2 classes)


---

## Today's class

| Time        | Content                             |
|-------------|-------------------------------------|
| 11:00-11:15 | Language and Modelling              |
| 11:15-11:45 | Tokenization, Stop Words &amp; Stemming |
| 11:45-11:55 | Individual quiz/tutorial Part 1     |
| 11:55-12:00 | Break                               |
| 12:00-12:15 | Sentiment analysis                  |
| 12:15-12:30 | Document-Frequency Matrix           |
| 12:30-12:40 | Word Embeddings                     |
| 12:40-12:45 | Individual quiz/tutorial Part 2     |
| 12:45-13:15 | Individual on A3 with peer-review   |
| 13:15-14:00 | Individual problem Set              |


---

class: inverse, center, middle

# Textual Data: Natural Language Features


.footnote[Slides adapted from Hvitfeldt, E., &amp; Silge, J. (2021). *Supervised machine learning for text analysis in R*. Chapman and Hall/CRC. https://doi.org/10.1201/9781003093459
]

---
class: inverse, center, middle
# Introduction to these two weeks on Text Analysis

---

## Supervised Modeling for Text Analysis

### Modelling as a Statistical Practice

As seen .content-box-green[*modelling*] can include a wide range of activities; over these two weeks we introduce supervised or predictive modelling **using text data to make predictions about the world**.

### Types of Models (next week)

1. **Regression Models**: Predict numeric or continuous outcomes (e.g., predicting the year of a U.S. Supreme Court opinion based on its text).
2. **Classification Models**: Predict discrete outcomes or class labels (e.g., classifying news articles to study media bias).

---

## Supervised Modeling for Text Analysis

###  Importance of Text Data

Text data is vital across fieldsâ€”from healthcare to digital humanities and social sciences However, specialised methods are essential to transform natural language into a machine-readable format.

### Text Preprocessing (this week)

*This week* we explore typical preprocessing steps from scratch making language data ready for computation and modelling (which we will cover *next week*).


---
class: inverse, center, middle

# Language and modeling

---

## Introduction

- **Text Analysis and Linguistics**: Machine learning and deep learning models are powerful tools for text analysis, but they are fundamentally shaped by human understanding of language.

- **Bridging the Gap**: Data scientists, often without formal training in linguistics, can benefit greatly from understanding how language works to build more effective text analysis models.

---

## The Role of Linguistics in Text-Based Machine Learning

### Why Linguistics Matters:

- Language is complex, ambiguous, and contextual, impacting the reliability of machine learning models.

  - "Include Your Children When Baking Cookies"

- By leveraging linguistic knowledge, we **create better features** that allow models to handle nuances in text data.

**Example**: Understanding sentence structures or word formations can lead to more accurate text representations in models.

---

## A text analysis pipeline

<div class="grViz html-widget html-fill-item" id="htmlwidget-a801e281baf078832a0f" style="width:100%;height:288px;"></div>
<script type="application/json" data-for="htmlwidget-a801e281baf078832a0f">{"x":{"diagram":"\ndigraph text_analysis_workflow {\n  \n  # Define graph attributes\n  graph [layout = dot, rankdir = LR]\n  \n  # Define node styles and labels\n  node [shape = box, style = filled, color = lightgrey]\n  \n  text_data      [label = \"Text Data\"]\n  preprocessing  [label = \"Preprocessing:\nCleaning,\nTokenization,\nStemming,\nRemoving \nStop words\"]\n  feature_extraction [label = \"Feature Extraction\"]\n  model          [label = \"Model\"]\n  classification  [label = \"Classification\"]\n  prediction     [label = \"Prediction\"]\n  \n  # Define edges to show the flow\n  text_data -> preprocessing\n  preprocessing -> feature_extraction\n  feature_extraction -> model\n  model -> classification\n  model -> prediction\n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>


---

## Key Linguistic Subfields Relevant to Text Analysis

Text processing benefits from understanding different linguistic levels, from sounds to sentence structure.

| Subfield      | Focus                                 | Example Usage in Text Analysis               |
|---------------|---------------------------------------|----------------------------------------------|
| Phonetics     | Sounds used in language               | N/A for text (but relevant for speech data)  |
| Morphology    | Structure and formation of words      | Stemming, lemmatization                      |
| Syntax        | Formation of sentences                | Part-of-speech tagging, dependency parsing   |
| Semantics     | Meaning of words and sentences        | Sentiment analysis                           |
| Pragmatics    | Contextual language use               | Disambiguation, context analysis             |

---

## Morphology - Transforming Words for Analysis


.content-box-yellow[

**Morphology** studies the structure of words, including morphemes, which are the smallest units of meaning.

]

Different languages vary in their use of morphemes, impacting model performance based on language-specific processing needs.

**Example**: English has fewer morphemes per word, while languages like Turkish and Russian have more, influencing how we preprocess text for each.

---

## Morphological Processing in R - Tokenization and Stemming (more on this later)

#### Step 1


``` r
library(tidytext)
library(SnowballC)

# Sample text
text &lt;- 
  c("Text analysis in machine learning can benefit from morphological processing.")
text_df &lt;- 
  data.frame(line = 1, text = text)
text_df
```

```
##   line
## 1    1
##                                                                           text
## 1 Text analysis in machine learning can benefit from morphological processing.
```

---

#### Step 2


``` r
# Tokenize text into individual words
tokens &lt;- text_df |&gt;
  tidytext::unnest_tokens(word, text)
tokens
```

```
##    line          word
## 1     1          text
## 2     1      analysis
## 3     1            in
## 4     1       machine
## 5     1      learning
## 6     1           can
## 7     1       benefit
## 8     1          from
## 9     1 morphological
## 10    1    processing
```

---

#### Step 3


``` r
# Apply stemming to reduce words to their root form
tokens |&gt;
  mutate(stem = SnowballC::wordStem(word))
```

```
##    line          word      stem
## 1     1          text      text
## 2     1      analysis   analysi
## 3     1            in        in
## 4     1       machine    machin
## 5     1      learning     learn
## 6     1           can       can
## 7     1       benefit   benefit
## 8     1          from      from
## 9     1 morphological morpholog
## 10    1    processing   process
```

---

## Morphological Processing in R - Tokenization and Stemming (more on this later)

1. **Tokenization**: Breaks down text into individual words (tokens).

2. **Stemming**: Reduces words to their base or *root* form, standardising variations (e.g., "running" to "run"). So words with the same *root* are comparable.


---

## Handling Language Diversity in Machine Learning Models

.content-box-red[

Machine learning models often fail to generalize across different languages or dialects.

]

- For example, a model trained on English may struggle with dialects like African American Vernacular English (AAVE), falsely identifying benign terms as harmful.

**Best Practice**:

- Explicitly state the language in model documentation.

- If working with multiple dialects, ensure the model includes training data representative of each.

---

## Text Context and Domain-Specific Language

- Text varies greatly by context; models trained on one type (e.g., tweets) may perform poorly on another (e.g., medical texts).

- For domain-specific tasks, tailored training data is crucial for accurate predictions.

**Example**: A sentiment model trained on social media text may misinterpret neutral medical terms as negative if applied to clinical documents.

**Best Practice**: Use context-specific text data for training to avoid bias and improve model performance.

---

## Limitations of Text-Based Models


- Text data cannot fully capture the **high-dimensional nature of language**, leading to inherent model limitations.

- Modelling assumes simplifications, which may omit crucial context or meaning.

**Implications**:

1. Accept that machine learning models have limitations based on the training data and the linguistic features used.

2. Regularly update and retrain models with recent, contextually relevant data to maintain accuracy.

---
class: inverse, center, middle

# Tokenization

---

## Tokenization - Turning Text into Tokens

**What for**? To Transform raw text into structured tokens to create features for machine learning.

### Overview

- Tokenization splits text into meaningful units (tokens) for computational analysis.

- Tokens can be words, characters, n-grams, and more.

---

## What is a Token?

.content-box-yellow[**Definition**: A token is a *unit of text*, often a word, used in analysis.]

**Examples**:

- **Character Tokens**: Individual letters (e.g., "m", "a", "c").
- **Word Tokens**: Single words (e.g., "machine").
- **Sentence Tokens**: Single sentence (e.g., "This machine is broken.").
- **Paragraph Tokens**: Single paragraph.
- **N-grams**: Sequences of words or characters.


---

## Tokenizing Text Data

**Objective**: Break down text for analysis using tokens.

**Example**: Let's use Mary Shelley's Frankestein for the analysis.


``` r
install.packages("gutenbergr")
```

Note: gutenbergr download books into data frames where each row is a book's line.


``` r
library(gutenbergr)
frankenstein &lt;- 
  gutenberg_works(title == "Frankenstein; Or, The Modern Prometheus") |&gt;
  gutenberg_download()
```

---

## Word Tokenization

**Purpose**: Split text into individual words.

We use the function `tokenize_words` from the *tokenizers* package to split the 49th line of the book.


``` r
install.packages("tokenizers")
```



``` r
frankenstein$text[49]
```

```
## [1] "The event on which this fiction is founded has been supposed, by Dr."
```



``` r
library(tokenizers)
word_tokens &lt;- tokenizers::tokenize_words(frankenstein$text[49])
word_tokens
```

```
## [[1]]
##  [1] "the"      "event"    "on"       "which"    "this"     "fiction" 
##  [7] "is"       "founded"  "has"      "been"     "supposed" "by"      
## [13] "dr"
```

---

## Tokenizing with tidytext

**Tidytext Workflow**: Convert text into tidy data for seamless analysis with dplyr.

.content-box-green[

Remember that tidy data is a data frame where each row is one observation (or unit of analysis) with its value.

]


``` r
install.packages("tidytext")
```

.small[

.pull-left[
In this example a row or unit of analysis is a single word.
]

.pull-right[
.center[

| line | word   |
|------|--------|
| 1    | machine|
| 1    | learning|
| 1    | in     |
| 1    | text   |
| 1    | analysis|
| 1    | is     |
| 1    | exciting|

]

]
]

---

## The three rules of tidy data

1. Each variable must have its own column.
2. Each observation must have its own row.
3. Each value must have its own cell.

&lt;img src = 'https://d33wubrfki0l68.cloudfront.net/6f1ddb544fc5c69a2478e444ab8112fb0eea23f8/91adc/images/tidy-1.png'&gt;&lt;/img&gt;

.footnote[Wickham, H., Ã‡etinkaya-Rundel, M., &amp; Grolemund, G. (2023). R for data science: Import, tidy, transform, visualize, and model data (2nd edition). Oâ€™Reilly Media, Inc. https://r4ds.had.co.nz/tidy-data.html]

---
.small[
The `unnest_tokens` function takes a tidy data frame where each row contains some text, here `text`, in a dedicated column and additional information (i.e., metadata), here `book` with the title of the book and return another tidy data frame where the text column is replaced by the tokenised text (in this case using "words").  
]


``` r
library(tidytext)
frankenstein |&gt; # From before
  tidytext::unnest_tokens(output = word, # Output column name
                          input = text, # Input column with text
                          token = "words") # Tokenize what?
```

```
## # A tibble: 72,841 Ã— 2
##    gutenberg_id word         
##           &lt;int&gt; &lt;chr&gt;        
##  1        41445 transcriberâ€™s
##  2        41445 note         
##  3        41445 this         
##  4        41445 text         
##  5        41445 was          
##  6        41445 produced     
##  7        41445 from         
##  8        41445 a            
##  9        41445 photo        
## 10        41445 reprint      
## # â„¹ 72,831 more rows
```

---

## Additional preprocessing of text

We can probably already do some cleaning, by removing all the lines that are not properly part of the book using the dplyr function `slice`.


``` r
frankenstein &lt;-
  frankenstein |&gt;
  dplyr::slice(46:dplyr::n()) 
  # this will only include rows from 46 to the last row.
  # which we get with the function `n()`
```


.content-box-red[

Preprocessing your text is critical. Text often comes with textual information you don't want to include because is not really part of the document.

]

- Preprocessing might also include set all characters to lower-case (this is done by the `unnest_tokens` function)

---

And after some cleaning we tokenize again but this time we use n-grams


``` r
library(tidytext)
frankenstein |&gt; # From before
  tidytext::unnest_tokens(output = word, # Output column name
                          input = text, # Input column with text
                          token = "ngrams", # Tokenize what?
                          n = 3) # How many grams?
```

```
## # A tibble: 61,592 Ã— 2
##    gutenberg_id word              
##           &lt;int&gt; &lt;chr&gt;             
##  1        41445 &lt;NA&gt;              
##  2        41445 &lt;NA&gt;              
##  3        41445 &lt;NA&gt;              
##  4        41445 the event on      
##  5        41445 event on which    
##  6        41445 on which this     
##  7        41445 which this fiction
##  8        41445 this fiction is   
##  9        41445 fiction is founded
## 10        41445 is founded has    
## # â„¹ 61,582 more rows
```

---

## Difference between `token = "words"` and `token = "ngrams"`

.small[

- Note that the word "preface", which now appears on the first row of the data frame `frankenstein` doesn't appear when we use tri-grams as is single word in its line. 

.pull-left[

#### Words


```
## # A tibble: 72,765 Ã— 2
##    gutenberg_id word   
##           &lt;int&gt; &lt;chr&gt;  
##  1        41445 preface
##  2        41445 the    
##  3        41445 event  
##  4        41445 on     
##  5        41445 which  
##  6        41445 this   
##  7        41445 fiction
##  8        41445 is     
##  9        41445 founded
## 10        41445 has    
## # â„¹ 72,755 more rows
```

]

.pull-right[

#### Trigrams (3-grams)


```
## # A tibble: 61,592 Ã— 2
##    gutenberg_id word              
##           &lt;int&gt; &lt;chr&gt;             
##  1        41445 &lt;NA&gt;              
##  2        41445 &lt;NA&gt;              
##  3        41445 &lt;NA&gt;              
##  4        41445 the event on      
##  5        41445 event on which    
##  6        41445 on which this     
##  7        41445 which this fiction
##  8        41445 this fiction is   
##  9        41445 fiction is founded
## 10        41445 is founded has    
## # â„¹ 61,582 more rows
```

]

]

---

## Understanding N-grams

.small[

**Definition**: N-grams are sequences of `\(n\)` words that capture phrase-level patterns.

Note that words in bi-grams and tri-grams overlap. 


``` r
frankenstein$text[4]
```

```
## [1] "The event on which this fiction is founded has been supposed, by Dr."
```

``` r
tokenize_ngrams(frankenstein$text[4], n = 2)
```

```
## [[1]]
##  [1] "the event"     "event on"      "on which"      "which this"   
##  [5] "this fiction"  "fiction is"    "is founded"    "founded has"  
##  [9] "has been"      "been supposed" "supposed by"   "by dr"
```

``` r
tokenize_ngrams(frankenstein$text[4], n = 3)
```

```
## [[1]]
##  [1] "the event on"       "event on which"     "on which this"     
##  [4] "which this fiction" "this fiction is"    "fiction is founded"
##  [7] "is founded has"     "founded has been"   "has been supposed" 
## [10] "been supposed by"   "supposed by dr"
```

]

---
class: inverse, center, middle

# Stop Words

---

## Introduction to Stop Words

### What are Stop Words?

- Common words in a language (e.g., "the," "and") that **carry little meaning** in NLP tasks.
- Removing stop words can simplify text data, improving model efficiency.

### History

- Term coined by Hans Peter Luhn in 1960.
- Initially used to reduce computation time in text mining.
- Yet, Stop Words might play an important role in specific text, for example in *stylometry*, which is used to predict the authorship of documents (e.g., finding that the author of The Cuckooâ€™s Calling was in fact J.K. Rowling).    

---

## Treating text as a collection of features

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/KS1xrYfGWuA?si=DKan_RMzt0F8i-JA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen&gt;&lt;/iframe&gt;

---

## Categories of Stop Words

### Types of Stop Words:

- **Global Stop Words**: Commonly uninformative words across many texts (e.g., "of," "in").
- **Subject-Specific Stop Words**: Words that lack meaning in specific contexts (e.g., "bedroom" in real estate listings).
- **Document Stop Words**: Low-information words unique to individual documents.

---

## Using Pre-Made Stop Word Lists

.small[

- Premade lists like SMART, Snowball, and onix contain common stop words.
- Different lists have varying lengths and words based on their intended use.


``` r
data(stop_words) # load the data from the tidytext package
```

You can access "standard" lists of Stop Words using the `stop_words` data frame.

.pull-left[


``` r
head(stop_words)
```

```
## # A tibble: 6 Ã— 2
##   word      lexicon
##   &lt;chr&gt;     &lt;chr&gt;  
## 1 a         SMART  
## 2 a's       SMART  
## 3 able      SMART  
## 4 about     SMART  
## 5 above     SMART  
## 6 according SMART
```

]

.pull-right[


``` r
table(stop_words$lexicon)
```

```
## 
##     onix    SMART snowball 
##      404      571      174
```

]




]

---

## Removing Stop Words with R



``` r
library(dplyr)
library(tidytext)
text_data &lt;- data.frame(text = "The quick brown fox jumps over the lazy dog")
text_data &lt;- text_data |&gt; tidytext::unnest_tokens(word, text)

# Remove stop words using Snowball list
clean_text &lt;- 
  text_data |&gt;
  dplyr::anti_join(stop_words) # return all rows from x without a match in y.
print(clean_text)
```

```
##    word
## 1 quick
## 2 brown
## 3   fox
## 4 jumps
## 5  lazy
## 6   dog
```


---

## More on joining tables with dplyr

.center[&lt;img src = "https://tavareshugo.github.io/r-intro-tidyverse-gapminder/fig/07-dplyr_joins.svg"&gt;&lt;/img&gt;]


---

## Creating Custom Stop Word Lists

### Why Customise?

.small[

Premade lists may not fit your dataset's unique requirements.

**Steps to Customise**:

1. Identify high-frequency words that add no value to your model.
2. Tailor the list to your domain (e.g., removing all animal names).


``` r
# Custom stop words for real estate
custom_stopwords &lt;- data.frame(word = "fox", "dog") # col name is important!
filtered_data &lt;- text_data |&gt; dplyr::anti_join(custom_stopwords)
print(filtered_data)
```

```
##    word
## 1   the
## 2 quick
## 3 brown
## 4 jumps
## 5  over
## 6   the
## 7  lazy
## 8   dog
```

]

---

## Considerations and Limitations

**Key Takeaways**:

- Stop word removal reduces data complexity but may lose context-specific information.
- Always review premade stop word lists for accuracy and bias.
- Experiment with different stop word lists and document the impact on model performance (and results).

---
class: inverse, center, middle

# Stemming

---

## Introduction to Stemming

### What is Stemming?

- Stemming reduces words to their base or root form, known as the "stem."
= Helps to group variations of words, such as "tree" and "trees."

.content-box-yellow[

**Purpose**: Simplifies text by reducing different forms of a word, decreasing the feature space.

]

(Remember that quantitative text analysis is all about bringing your texts into a **feature space** that you define).

---

## The Porter Stemming Algorithm

- Most widely-used stemming algorithm for English, available via the *SnowballC* package in R.
- Rules-based algorithm that systematically reduces words (e.g., "stories" becomes "stori").


``` r
library(SnowballC)
SnowballC::wordStem(c("win", "winning", "winner"))
```

```
## [1] "win"    "win"    "winner"
```


---

## Chaining tokenisation, stopwords and stemming in the same pipeline


``` r
frankenstein_tokens &lt;- 
  frankenstein |&gt;
  # Tokenization
  tidytext::unnest_tokens(output = word, input = text, 
                          token = "words", to_lower = TRUE) |&gt;
  # Removing stop words
  dplyr::anti_join(stop_words) |&gt;
  # Stemming
  dplyr::mutate(stemmed_word = SnowballC::wordStem(word))
```

---

``` r
head(frankenstein_tokens)
```

```
## # A tibble: 6 Ã— 3
##   gutenberg_id word     stemmed_word
##          &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;       
## 1        41445 preface  prefac      
## 2        41445 event    event       
## 3        41445 fiction  fiction     
## 4        41445 founded  found       
## 5        41445 supposed suppos      
## 6        41445 dr       dr
```

---

## Should You Use Stemming?

- Stemming can reduce data sparsity but may discard important details.
- Not always beneficial for certain text models, as it may overgeneralise.
- In topic modeling, aggressive stemming can reduce coherence and topic stability.


---

## Difference Between Stemming and Lemmatisation

### Stemming:

- Reduces words to their base form without regard to meaning or grammatical role.
- **Example**: "stories" -&gt; "stori"

### Lemmatization:

- Converts words to their dictionary form (lemma) based on context.
- Requires linguistic knowledge (e.g., part of speech) for accuracy.
- **Example**: "running" -&gt; "run"

---

class: inverse, center, middle

# Individual quiz/tutorial Part 1 
(to Stemming included)

<div class="countdown" id="timer_ad022ee3" data-update-every="1" tabindex="0" style="right:0;bottom:0;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">10</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
class: inverse, center, middle

# Sentiment analysis


---

We already have the tools to conduct some simple sentiment analysis. 

## Sentiment analysis

### What is Sentiment Analysis?

- A technique to determine the emotional tone (e.g., positive, negative, neutral) of text data.
- Useful in understanding public opinion, customer feedback, social media posts, etc.

.content-box-yellow[
Sentiment analysis is about associating the words of a document with a **dictionary** where words are described in terms of sentiments, either on a continuous scale (from negative to positive) or with categories.
]

---

## Types of lexicons (or dictionaries) for sentiment analysis 

.small[

Let's downland four lexicons available with the tidytext package


``` r
sent_bing &lt;- tidytext::get_sentiments(lexicon = "bing")
sent_afinn &lt;- tidytext::get_sentiments(lexicon = "afinn")
sent_loughran &lt;- tidytext::get_sentiments(lexicon = "loughran")
sent_nrc &lt;- tidytext::get_sentiments(lexicon = "nrc")
```


``` r
nrow(sent_bing)
```

```
## [1] 6786
```

``` r
nrow(sent_afinn)
```

```
## [1] 2477
```

``` r
nrow(sent_loughran)
```

```
## [1] 4150
```

``` r
nrow(sent_nrc)
```

```
## [1] 13872
```

]
---


``` r
sent_bing %&gt;%
  dplyr::sample_n(15)
```

```
## # A tibble: 15 Ã— 2
##    word              sentiment
##    &lt;chr&gt;             &lt;chr&gt;    
##  1 mercifully        positive 
##  2 misrepresentation negative 
##  3 quiet             positive 
##  4 flawlessly        positive 
##  5 tingle            positive 
##  6 unproved          negative 
##  7 pardon            positive 
##  8 shocked           negative 
##  9 attentive         positive 
## 10 allege            negative 
## 11 drones            negative 
## 12 dislike           negative 
## 13 repugnance        negative 
## 14 shameless         negative 
## 15 hiss              negative
```

---


``` r
sent_afinn %&gt;%
  dplyr::sample_n(15)
```

```
## # A tibble: 15 Ã— 2
##    word            value
##    &lt;chr&gt;           &lt;dbl&gt;
##  1 racism             -3
##  2 terrorizes         -3
##  3 ominous             3
##  4 anti               -1
##  5 interruption       -2
##  6 errors             -2
##  7 humiliation        -3
##  8 brave               2
##  9 warmth              2
## 10 gag                -2
## 11 perfectly           3
## 12 grand               3
## 13 indignant          -2
## 14 justice             2
## 15 right direction     3
```

---


``` r
sent_loughran %&gt;%
  dplyr::sample_n(15)
```

```
## # A tibble: 15 Ã— 2
##    word          sentiment   
##    &lt;chr&gt;         &lt;chr&gt;       
##  1 prohibit      constraining
##  2 objectionably negative    
##  3 might         uncertainty 
##  4 unfunded      negative    
##  5 debarments    negative    
##  6 entails       constraining
##  7 illegality    negative    
##  8 alienated     negative    
##  9 forfeits      negative    
## 10 distressed    negative    
## 11 convictions   litigious   
## 12 relinquishes  negative    
## 13 overbuild     negative    
## 14 almost        uncertainty 
## 15 excessive     negative
```

---


``` r
sent_nrc %&gt;%
  dplyr::sample_n(15)
```

```
## # A tibble: 15 Ã— 2
##    word          sentiment   
##    &lt;chr&gt;         &lt;chr&gt;       
##  1 anarchist     anger       
##  2 supplies      positive    
##  3 elf           disgust     
##  4 unfriendly    anger       
##  5 baptism       positive    
##  6 goodness      surprise    
##  7 restorative   joy         
##  8 sonata        positive    
##  9 smitten       positive    
## 10 unsurpassed   joy         
## 11 sin           fear        
## 12 weary         negative    
## 13 entertaining  anticipation
## 14 productivity  positive    
## 15 transcendence positive
```

---

## Let's compare the sentiment in the 2016 US presidential debate

Let's load the data first...


``` r
load("../data/debate_transcripts.rda")
```


``` r
head(debate_transcripts)
```

```
## # A tibble: 6 Ã— 6
##   speaker           text                type  election_year date       candidate
##   &lt;chr&gt;             &lt;chr&gt;               &lt;chr&gt;         &lt;dbl&gt; &lt;date&gt;         &lt;dbl&gt;
## 1 Dorothy Ridings   Good evening from â€¦ VP             1984 1984-10-11         0
## 2 Sander Vanocur    Thank you, Dorothyâ€¦ VP             1984 1984-10-11         0
## 3 John Mashek       John Adams, our naâ€¦ VP             1984 1984-10-11         0
## 4 George H. W. Bush Well, I dont thinkâ€¦ VP             1984 1984-10-11         1
## 5 John Mashek       Well some Republicâ€¦ VP             1984 1984-10-11         0
## 6 George H. W. Bush I owe my presidentâ€¦ VP             1984 1984-10-11         1
```

---

## Donald Trump sentiment in 2016 (AFINN)


``` r
trump_2016_afinn &lt;- 
  debate_transcripts |&gt;
  dplyr::filter(speaker == "Donald Trump", election_year == 2016) |&gt;
  tidytext::unnest_tokens(output = word, input = text, 
                          token = "words", to_lower = TRUE) |&gt;
  # Removing stop words
  dplyr::anti_join(stop_words) |&gt;
  # Add sentiment
  dplyr::inner_join(sent_afinn)
trump_2016_afinn
```

```
## # A tibble: 1,246 Ã— 7
##    speaker      type  election_year date       candidate word      value
##    &lt;chr&gt;        &lt;chr&gt;         &lt;dbl&gt; &lt;date&gt;         &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt;
##  1 Donald Trump Pres           2016 2016-10-19         1 justice       2
##  2 Donald Trump Pres           2016 2016-10-19         1 forced       -1
##  3 Donald Trump Pres           2016 2016-10-19         1 apologize    -1
##  4 Donald Trump Pres           2016 2016-10-19         1 apologize    -1
##  5 Donald Trump Pres           2016 2016-10-19         1 win           4
##  6 Donald Trump Pres           2016 2016-10-19         1 trauma       -3
##  7 Donald Trump Pres           2016 2016-10-19         1 angry        -3
##  8 Donald Trump Pres           2016 2016-10-19         1 angry        -3
##  9 Donald Trump Pres           2016 2016-10-19         1 justice       2
## 10 Donald Trump Pres           2016 2016-10-19         1 upset        -2
## # â„¹ 1,236 more rows
```

---

## Hillary Clinton sentiment in 2016 (AFINN)


``` r
clinton_2016_afinn &lt;- 
  debate_transcripts |&gt;
  dplyr::filter(speaker == "Hillary Clinton", election_year == 2016) |&gt;
  tidytext::unnest_tokens(output = word, input = text, 
                          token = "words", to_lower = TRUE) |&gt;
  # Removing stop words
  dplyr::anti_join(stop_words) |&gt;
  # Add sentiment
  dplyr::inner_join(sent_afinn)
clinton_2016_afinn
```

```
## # A tibble: 1,565 Ã— 7
##    speaker         type  election_year date       candidate word          value
##    &lt;chr&gt;           &lt;chr&gt;         &lt;dbl&gt; &lt;date&gt;         &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;
##  1 Hillary Clinton Pres           2016 2016-10-19         1 opportunities     2
##  2 Hillary Clinton Pres           2016 2016-10-19         1 powerful          2
##  3 Hillary Clinton Pres           2016 2016-10-19         1 wealthy           2
##  4 Hillary Clinton Pres           2016 2016-10-19         1 united            1
##  5 Hillary Clinton Pres           2016 2016-10-19         1 undermined       -2
##  6 Hillary Clinton Pres           2016 2016-10-19         1 united            1
##  7 Hillary Clinton Pres           2016 2016-10-19         1 powerful          2
##  8 Hillary Clinton Pres           2016 2016-10-19         1 opportunity       2
##  9 Hillary Clinton Pres           2016 2016-10-19         1 hope              2
## 10 Hillary Clinton Pres           2016 2016-10-19         1 consents          2
## # â„¹ 1,555 more rows
```

---

## Who's more using more negative terms?


``` r
median(trump_2016_afinn$value)
```

```
## [1] -1
```

``` r
mean(trump_2016_afinn$value)
```

```
## [1] -0.3170144
```


``` r
median(clinton_2016_afinn$value)
```

```
## [1] 1
```

``` r
mean(clinton_2016_afinn$value)
```

```
## [1] 0.1290735
```

---

## Donald Trump sentiment in 2016 (NRC)


``` r
trump_2016_nrc &lt;- 
  debate_transcripts |&gt;
  dplyr::filter(speaker == "Donald Trump", election_year == 2016) |&gt;
  tidytext::unnest_tokens(output = word, input = text, 
                          token = "words", to_lower = TRUE) |&gt;
  # Removing stop words
  dplyr::anti_join(stop_words) |&gt;
  # Add sentiment
  dplyr::inner_join(sent_nrc)
trump_2016_nrc
```

```
## # A tibble: 5,612 Ã— 7
##    speaker      type  election_year date       candidate word          sentiment
##    &lt;chr&gt;        &lt;chr&gt;         &lt;dbl&gt; &lt;date&gt;         &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt;    
##  1 Donald Trump Pres           2016 2016-10-19         1 supreme       positive 
##  2 Donald Trump Pres           2016 2016-10-19         1 court         anger    
##  3 Donald Trump Pres           2016 2016-10-19         1 court         anticipaâ€¦
##  4 Donald Trump Pres           2016 2016-10-19         1 court         fear     
##  5 Donald Trump Pres           2016 2016-10-19         1 justice       positive 
##  6 Donald Trump Pres           2016 2016-10-19         1 justice       trust    
##  7 Donald Trump Pres           2016 2016-10-19         1 inappropriate anger    
##  8 Donald Trump Pres           2016 2016-10-19         1 inappropriate disgust  
##  9 Donald Trump Pres           2016 2016-10-19         1 inappropriate negative 
## 10 Donald Trump Pres           2016 2016-10-19         1 inappropriate sadness  
## # â„¹ 5,602 more rows
```

---

## Hillary Clinton sentiment in 2016 (NRC)


``` r
clinton_2016_nrc &lt;- 
  debate_transcripts |&gt;
  dplyr::filter(speaker == "Hillary Clinton", election_year == 2016) |&gt;
  tidytext::unnest_tokens(output = word, input = text, 
                          token = "words", to_lower = TRUE) |&gt;
  # Removing stop words
  dplyr::anti_join(stop_words) |&gt;
  # Add sentiment
  dplyr::inner_join(sent_nrc)
clinton_2016_nrc
```

```
## # A tibble: 7,038 Ã— 7
##    speaker         type  election_year date       candidate word     sentiment  
##    &lt;chr&gt;           &lt;chr&gt;         &lt;dbl&gt; &lt;date&gt;         &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;      
##  1 Hillary Clinton Pres           2016 2016-10-19         1 talk     positive   
##  2 Hillary Clinton Pres           2016 2016-10-19         1 supreme  positive   
##  3 Hillary Clinton Pres           2016 2016-10-19         1 court    anger      
##  4 Hillary Clinton Pres           2016 2016-10-19         1 court    anticipatiâ€¦
##  5 Hillary Clinton Pres           2016 2016-10-19         1 court    fear       
##  6 Hillary Clinton Pres           2016 2016-10-19         1 provide  positive   
##  7 Hillary Clinton Pres           2016 2016-10-19         1 provide  trust      
##  8 Hillary Clinton Pres           2016 2016-10-19         1 strongly positive   
##  9 Hillary Clinton Pres           2016 2016-10-19         1 supreme  positive   
## 10 Hillary Clinton Pres           2016 2016-10-19         1 court    anger      
## # â„¹ 7,028 more rows
```

---

.pull-left[


``` r
trump_2016_nrc |&gt;
  ggplot(aes(x = sentiment)) +
  geom_bar() +
  scale_x_discrete(guide = guide_axis(angle = 45))
```

&lt;img src="week-10_files/figure-html/unnamed-chunk-40-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

.pull-right[


``` r
clinton_2016_nrc |&gt;
  ggplot(aes(x = sentiment)) +
  geom_bar() +
  scale_x_discrete(guide = guide_axis(angle = 45))
```

&lt;img src="week-10_files/figure-html/unnamed-chunk-41-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]



---
class: inverse, center, middle

# The Document-Frequency Matrix

---

## The Document-Frequency Matrix

Let's say you have six *documents* you want to analyse. These six documents constitute your **collection** (a.k.a. **corpus**).


``` r
documents &lt;- c(
  "Political parties influence policy decisions",
  "Elections determine the political landscape",
  "Governments implement policies for public welfare",
  "Economic growth depends on consumer spending",
  "Inflation affects purchasing power in the economy",
  "Fiscal policy aims to stabilize economic fluctuations"
)
```

--

- **Problem**: you must **quantify** these documents **within the same space** so that you can analyse them together.

- **Solution**: You can **count the frequency of each word** in each document (and create a document-frequency matrix, or DFM)!

---

## The Document-Frequency Matrix (DFM) in R

Step 1. Our documents into a tidy data frame


``` r
text_data &lt;- 
  data.frame(doc_id = 1:6, text = documents) # Our six documents are now in a df
```

Step 2. Let's count the **frequency of each word in each document**


``` r
my_word_frequency &lt;- 
  text_data %&gt;%
  tidytext::unnest_tokens(word, text) |&gt; # 1. Tokenise the documents
  dplyr::anti_join(stop_words) |&gt; # 2. Remove Stop Words
  dplyr::count(doc_id, word)
head(my_word_frequency)
```

```
##   doc_id      word n
## 1      1 decisions 1
## 2      1 influence 1
## 3      1   parties 1
## 4      1    policy 1
## 5      1 political 1
## 6      2 determine 1
```

---

Step 2-b Let's count the **frequency of each word in Trump and Clinton**


``` r
trump_clinton_2016_freq &lt;-
  debate_transcripts |&gt;
  dplyr::filter(speaker %in% c("Donald Trump",
                               "Hillary Clinton"), 
                election_year == 2016) |&gt;
  tidytext::unnest_tokens(output = word, input = text, 
                          token = "words", to_lower = TRUE) |&gt;
  # Removing stop words
  dplyr::anti_join(stop_words) |&gt;
  dplyr::count(speaker, word)
head(trump_clinton_2016_freq)
```

```
## # A tibble: 6 Ã— 3
##   speaker      word      n
##   &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;
## 1 Donald Trump 000      22
## 2 Donald Trump 04        1
## 3 Donald Trump 1        22
## 4 Donald Trump 10       11
## 5 Donald Trump 100      10
## 6 Donald Trump 104       1
```

---


``` r
trump_clinton_2016_freq |&gt;
  group_by(speaker) |&gt;
  slice_max(n, n = 15) |&gt;
  ungroup() |&gt;
  ggplot(aes(n, fct_reorder(word, n), fill = speaker)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~speaker, ncol = 2, scales = "free") +
  labs(x = "frequency", y = NULL)
```

&lt;img src="week-10_files/figure-html/unnamed-chunk-46-1.svg" width="70%" style="display: block; margin: auto;" /&gt;



---

Step 3. Let's create the document-term matrix

.small[


``` r
my_dfm &lt;- 
  my_word_frequency |&gt;
  # This requries install.packages('quanteda')
  tidytext::cast_dfm(document = doc_id, # Column identifying the document
                     term = word, # Column identifying the term
                     value = n) # Column identifying the frequency value
print(my_dfm)
```

```
## Document-feature matrix of: 6 documents, 27 features (81.48% sparse) and 0 docvars.
##     features
## docs decisions influence parties policy political determine elections landscape
##    1         1         1       1      1         1         0         0         0
##    2         0         0       0      0         1         1         1         1
##    3         0         0       0      0         0         0         0         0
##    4         0         0       0      0         0         0         0         0
##    5         0         0       0      0         0         0         0         0
##    6         0         0       0      1         0         0         0         0
##     features
## docs governments implement
##    1           0         0
##    2           0         0
##    3           1         1
##    4           0         0
##    5           0         0
##    6           0         0
## [ reached max_nfeat ... 17 more features ]
```

DFM is commonly used but also inefficient because **sparse** (it's mostly zeros!).

]

---

## Term Frequency-Inverse Document Frequency

So far we have created a document-frequency matrix using the simple frequency of words in a document. If a word (or term) appears 4 times in a document, the reported value will be 4. 

Yet it is probably possible to do better than that especially if we want to identify and weight up words that are more important to set documents apart.

- Think about words that only appears in one or two documents, and non in the rest of the corpus.

**Definition**: TF-IDF stands for .content-box-yellow[Term Frequency-Inverse Document Frequency], a statistical measure used to evaluate the importance of a word in a document relative to a collection (corpus) of documents.

**Purpose**: Highlights words that are unique or distinctive to specific documents while down-weighting common words (e.g., "the," "and").

---

## Understanding Term Frequency (TF) and Inverse Document Frequency (IDF)

- **Term Frequency (TF)**: Measures how often a word appears in a document.

`$$TF = \frac{\text{Total terms in document}}{Number of times term appears in document}$$`

- **Inverse Document Frequency (IDF)**: Reduces the weight of terms that frequently appear across many documents.

$$IDF = log \left( \frac{\text{Total number of documents}}{\text{Number of documents containing term}} \right) $$

 
---

## Calculating TF-IDF

`$$TF-IDF=TF\timesIDF$$`

### Interpretation:

- **High TF-IDF scores**: Words that are unique to a particular document and carry more meaning within that context.
- **Low TF-IDF scores**: Common words across the corpus, often less meaningful for distinguishing documents.

### Example:

Words like "algorithm" in a tech-focused document corpus will have higher TF-IDF scores than words like "the" or "is."

---

## TF-IDF in R

To calculate TF-IDF you can use `bind_tf_idf()` from the tidytext package


``` r
my_word_tfidf &lt;- 
  text_data |&gt;
  tidytext::unnest_tokens(word, text) |&gt; # 1. Tokenise the documents
  dplyr::filter(!word %in% stopwords::stopwords()) |&gt; # 2. Remove Stop Words
  dplyr::count(doc_id, word) |&gt; # 3. Count the frequency
  tidytext::bind_tf_idf(word, doc_id, n) # 4. Calculate and Bind TF-IDF column
head(my_word_tfidf)
```

```
##   doc_id      word n   tf      idf    tf_idf
## 1      1 decisions 1 0.20 1.791759 0.3583519
## 2      1 influence 1 0.20 1.791759 0.3583519
## 3      1   parties 1 0.20 1.791759 0.3583519
## 4      1    policy 1 0.20 1.098612 0.2197225
## 5      1 political 1 0.20 1.098612 0.2197225
## 6      2 determine 1 0.25 1.791759 0.4479399
```

---

You can then create your document-term matrix with the same function seen above (`tidytext::cast_dfm()`).


``` r
my_word_tfidf |&gt;
    tidytext::cast_dfm(document = doc_id, # Column identifying the document
                     term = word, # Column identifying the term
                     value = tf_idf) # Column identifying the frequency value
```

```
## Document-feature matrix of: 6 documents, 27 features (81.48% sparse) and 0 docvars.
##     features
## docs decisions influence   parties    policy political determine elections
##    1 0.3583519 0.3583519 0.3583519 0.2197225 0.2197225 0         0        
##    2 0         0         0         0         0.2746531 0.4479399 0.4479399
##    3 0         0         0         0         0         0         0        
##    4 0         0         0         0         0         0         0        
##    5 0         0         0         0         0         0         0        
##    6 0         0         0         0.1831020 0         0         0        
##     features
## docs landscape governments implement
##    1 0           0         0        
##    2 0.4479399   0         0        
##    3 0           0.3583519 0.3583519
##    4 0           0         0        
##    5 0           0         0        
##    6 0           0         0        
## [ reached max_nfeat ... 17 more features ]
```

---

- **Problem**: Sparse matrices are memory-intensive and unsuitable for capturing context. Instead...
- **Solution**: Word embeddings capture semantics by learning word relationships (more efficiently than DFM).

&gt; "Modern word embeddings are based on a statistical approach to modeling language, rather than a linguistics or rules-based approach."

---
class: inverse, center, middle

# Word Embeddings

---

## What are embeddings?

.content-box-yellow[
**Embeddings** are a fundamental tool that bridges the gap between *qualitative* and *quantitative* dataâ€”especially useful in social sciences where important data is often textual or categorical (or visual).
]

- At their core, embeddings are **numerical representations** of data elements, such as words, sentences, documents, or even users, in a **continuous vector space**. 

- This means we **convert qualitative data into a series of numbers** (vectors) that a computer can process mathematically.

- For **Text Data**: Words or phrases are transformed into vectors of numbers.
- For **Categorical Data**: Categories or classes are represented in a numerical format that *preserves their relationships*.

---

## Why Do We Need Embeddings?

In data analytics, especially with machine learning algorithms, we need numerical inputs. Embeddings allow us to:

- **Capture Semantic Meaning**: Words with similar meanings have vectors that are close together in the embedding space.
- **Perform Mathematical Operations**: Enable calculations like measuring similarity or clustering data points.
- **Reduce Dimensionality**: Compress high-dimensional data (with a too many features) into lower-dimensional space without losing significant information.

---
## How Do Embeddings Work?

.small[

#### 1. Representing Data in Vector Space

- Imagine a multi-dimensional space where each dimension represents a **feature** of the data.

- Each data element is a point in this space, defined by its **vector coordinates**.

#### 2. Training Embeddings

- Embeddings are learned from data using neural networks or other machine learning models.

- Example: In natural language processing (NLP), models like Word2Vec are trained on large text corpora to learn word embeddings based on context.

#### 3. Contextual Relationships

- The position of each vector reflects the relationships between data elements.

- **Semantic Proximity**: Words that appear in similar contexts are located near each other in the vector space.

]
---

## Analogies to Understand Embeddings

.content-box-yellow[

###Think of Embeddings Like a Map

- Cities and Distances: Each city is a point on a map with geographic coordinates. The distance between cities tells you how close they are geographically - if they are really close they might be part of the same community (e.g., state or nation).

]


---

## Introduction to Word Embeddings

.content-box-yellow[

**Definition**: Word embeddings are dense vector representations of words that capture semantic meaning based on context.

]

&gt; "You shall know a word by the company it keeps." â€” John Rupert Firth

## But why do need word embeddings?

Traditional text representations are sparse and high-dimensional. Word embeddings provide a dense, low-dimensional alternative that captures semantic similarity.

---

## Creating Word Embeddings â€“ An Overview

Process: Word embeddings are learned by analysing the co-occurrence of words in a large text corpus.

- **Step 1**: Process the corpus and identify word contexts (e.g., via sliding windows).
- **Step 2**: Measure word association using statistical methods, such as Pointwise Mutual Information (PMI).
- **Step 3**: Apply dimensionality reduction techniques (e.g., Singular Value Decomposition, SVD) to create embeddings.

---

## The Concept of Context â€“ The Role of Windows

### What is a Sliding Window?

- A **window** is a defined span of text around each word, allowing the model to "see" a word's immediate neighbours.

**Example**: In "The cat sat on the mat," a window size of 2 around "sat" includes ["cat", "on"].

**Purpose**: Windows capture the local context around each word, encoding relationships that influence semantic meaning.

---

## How Windows Affect Word Embeddings

### Window Size Implications:

- **Small Windows** (e.g., 2-3 words): Capture *functional similarity*, such as words with similar grammatical roles (e.g., verbs near "run").
- **Large Windows** (e.g., 10+ words): Capture **topical similarity**, meaning words related to the same theme or subject.
**Key Insight**: Window size influences the type of relationship captured by embeddings, from grammatical to semantic.

---

## Creating Custom Embeddings â€“ Window-Based Context

### How It Works:

- For each word in a text corpus, the model looks within a defined window to learn which words commonly co-occur.
- Word pairs found within these windows influence the final vector representation of each word.

### Why This Matters:

**Windows help embeddings differentiate between words** with different contexts or meanings (e.g., "bank" in finance vs. nature).

---

## Word Co-Occurrence â€“ Context in Action

### Pointwise Mutual Information (PMI):

- A statistical measure used to calculate how often two words appear together within a window.
- Higher PMI values indicate strong associations (e.g., "coffee" and "cup").

**Result**: Words with high co-occurrence within windows gain similar vector representations, capturing context-specific meaning.

---

## Pre-Trained Word Embeddings â€“ An Overview

### What Are They?

- Pre-trained embeddings are word vectors learned from large, publicly available corpora like Wikipedia or news articles.

- Examples include GloVe, Word2Vec, and FastText.

---

## Use Pre-Trained Word Embeddings in R

Refer to the text book for more details, but note that Pre-Trained models can be very large (GB large).

For example, 

- the `embedding_glove6b()` function of the textdata package will download a 6 billion tokens model (size: 822.2 MB)

- the `embedding_glove840b()` function will download a 840 billion token models 4.03 GB

Once downloaded, you can use the vectors for the words of your corpus for your analysis (instead of calculating these vectors yourself)

---
class: inverse, center, middle

# Individual quiz/tutorial Part 2

<div class="countdown" id="timer_712f36be" data-update-every="1" tabindex="0" style="right:0;bottom:0;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
class: inverse, center, middle

# Individual on A3 with peer-review

<div class="countdown" id="timer_8b463f3d" data-update-every="1" tabindex="0" style="right:0;bottom:0;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">30</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
class: inverse, center, middle

# Individual problem set


---
class: inverse, center, middle

# Attendance

---
class: inverse, center, middle

# See you next week for the second week on Text Analysis!


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="assets/remark-zoom.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "4:3",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
