<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>SSPS [4102|6006] Data Analytics[in the Social Sciences|for Social Research]</title>
    <meta charset="utf-8" />
    <meta name="author" content="Francesco Bailo" />
    <script src="week-07_files/header-attrs/header-attrs.js"></script>
    <link href="week-07_files/remark-css/default.css" rel="stylesheet" />
    <link href="week-07_files/htmltools-fill/fill.css" rel="stylesheet" />
    <script src="week-07_files/htmlwidgets/htmlwidgets.js"></script>
    <script src="week-07_files/viz/viz.js"></script>
    <link href="week-07_files/DiagrammeR-styles/styles.css" rel="stylesheet" />
    <script src="week-07_files/grViz-binding/grViz.js"></script>
    <link href="week-07_files/countdown/countdown.css" rel="stylesheet" />
    <script src="week-07_files/countdown/countdown.js"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        TeX: { equationNumbers: { autoNumber: "AMS" } },
      });
    </script>
    <style>
    .mjx-mrow a {
      color: black;
      pointer-events: none;
      cursor: default;
    }
    </style>
    <link rel="stylesheet" href="assets/sydney-fonts.css" type="text/css" />
    <link rel="stylesheet" href="assets/sydney.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# SSPS [4102|6006] Data Analytics</br>[in the Social Sciences|for Social Research]
]
.subtitle[
## Week 07</br>Probability
]
.author[
### Francesco Bailo
]
.date[
### Semester 1, 2025 (updated: 2025-02-07)
]

---


background-image: url('assets/USydLogo.svg')
background-size: 95%

&lt;style&gt;
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
&lt;/style&gt;



---

## Acknowledgement of Country

I would like to acknowledge the Traditional Owners of Australia and recognise their continuing connection to land, water and culture. The  University of Sydney is located on the land of the Gadigal people  of the Eora Nation. I pay my respects to their Elders, past and present.

---

## Recap from last week

- `lm()` with one independent variable.
- `\(R^2\)`, a model fit measure, which represents the proportion of variability in `\(Y\)` (outcome or dependent variable) that is explained by a linear combination of `\(X\)` (predictors or independent variables).  

---

## Today's class

| Time        | Content                                       |
|-------------|-----------------------------------------------|
| 11:00-11:30 | Lab: Multiple regression models and predict() |
| 11:30-11:40 | Individual quiz/tutorial Part 1               |
| 11:40-12:30 | Probability                                   |
| 12:30-12:45 | Break                                         |
| 12:45-13:00 | Individual quiz/tutorial Part 1               |
| 13:00-14:00 | Group in-class problem set                    |


---

## Housekeeping: Free Access to Data Camp courses, tracks and projects

- This is totally optional, and you should consider it if you want to put some extra time in developing your R skills

- Access Data Camp classroom [here](https://www.datacamp.com/groups/shared_links/3ffac39d779d15680cd302d21bd72ca5fb49857b85e87494a2c3ed8f2438642b) (create account using your USYD email)

- You should be able to access tracks, courses, and projects I have assigned to the team

- This is very much experimental, feedback on this very much appreciated!

.center[&lt;img src = 'https://lts.lehigh.edu/sites/default/files/field/image/DataCamp%20for%20LTS%20News.png' width = '50%'&gt;]



---
class: inverse, center, middle

# Before talking about probability, let's go back a bit and talk about multiple regression models ...

---

## Modelling relationships between variables

- A causal graphical model represent graphically variables and the vectors of causality that connect them (what causes what). 

- Each node is a random variable.

<div class="grViz html-widget html-fill-item" id="htmlwidget-98f3979fd4798d3ccb91" style="width:100%;height:288px;"></div>
<script type="application/json" data-for="htmlwidget-98f3979fd4798d3ccb91">{"x":{"diagram":"\n  digraph DAG {\n    graph [rankdir = LR]\n\n    # Nodes\n    A [label = \"Parent A\"]\n    B [label = \"Parent B\"]\n    C [label = \"Child C\"]\n\n    # Edges\n    A -> C\n    B -> C\n  }\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>


---

### NOW, using Padlet let's brainstorm a graphical model trying to address (also in terms of measurability) the BIG question of political science as of 2024. 

--

### Will Taylor Swiftâ€™s Endorsement Affect the US Election? A Causal Graphical Model

.center[

&lt;img src = '../img/padlet_week_07.png' width = '25%'&gt;

OR 

[click here or in Canvas](https://sydney.padlet.org/francescobailo/will-taylor-swift-s-endorsement-affect-the-us-election-a-cau-41qsn1lh63sz1fl6) 


]




---

## Multiple Linear Regression Models

Linear models with more than one `\(X\)` variable

`$$\widehat{Y}_i = \widehat{\alpha} + \widehat{\beta}_1 X_{i1}+... + \widehat{\beta}_p X_{ip}$$`

where:

- `\(\widehat{Y_i}\)` is the predicted value of `\(Y\)` for observation `\(i\)`

- `\(\widehat{\alpha}\)` is the estimated intercept coefficient  

 each `\(\widehat{\beta}_j\)` (pronounced beta hat sub j) is the estimated coefficient for variable `\(X_j\)` ( `\(j{=} {1}, ..., p\)` ) - we use `\(j\)` as a stand-in for all different subscripts.

- each `\(X_{ij}\)` is the observed value of the variable `\(X_j\)` for observation `\(i\)` ( `\(j{=} {1}, ..., p\)` )

- `\(p\)` is the total number of `\(X\)` variables in the model.

.footnote[Slide adapted from slides by Prof. Llaudet]


---

## Simple vs Multiple regression

.pull-left[

| simple regression                          |
|--------------------------------------------|
| `\(\widehat{Y} = \widehat{\alpha} + \widehat{\beta} X\)`  |
| `\(\widehat{\alpha}\)`: `\(\widehat{Y}\)` when `\(X=0\)` |
| `\(\widehat{\beta}\)`: `\(\triangle\widehat{Y}\)` associated with `\(\triangle X=1\)` |


]

.pull-right[

| multiple regression                                                             |
|---------------------------------------------------------------------------------|
| `\(\widehat{Y} = \widehat{\alpha} + \widehat{\beta}_{1} X_{1} + ... + \widehat{\beta}_p X_{p}\)`  |
| `\(\widehat{\alpha}\)`: `\(\widehat{Y}\)` when all `\(X_j=0\)` ( `\(j=1,...,p\)` ) |
| each `\(\widehat{\beta}_j\)`: `\(\triangle\widehat{Y}\)` associated with `\(\triangle X_j=1\)`, while holding all other `\(X\)` variables constant or *ceteris paribus* |


]

.footnote[Slide adapted from slides by Prof. Llaudet]

---

## Interpretation of Coefficients in Multiple Linear Regression Models

`$$\widehat{Y} = \widehat{\alpha} + \widehat{\beta}_{1} X_{1} + ... + \widehat{\beta}_p X_{p}$$`

- `\(\widehat{\alpha}\)` is the `\(\widehat{Y}\)` when *all* `\(X_j{=}{0}\)`

- Because there are multiple `\(X\)` variables, there are multiple `\(\widehat{\beta}\)` coefficients (one for each `\(X\)` variable)

.content-box-yellow[

- Each `\(\widehat{\beta}_j\)` is the `\(\triangle \widehat{Y}\)` associated with `\(\triangle X_j\)`=1, *while holding all other `\(X\)` variables constant* 

]

.footnote[Slide adapted from slides by Prof. Llaudet]
---
class: inverse, center, middle

# Lab: lm() with multiple regression

---

## US midterm elections data&lt;sup&gt;1&lt;/sup&gt;

| Variable name | Description |
| ------------- | ----------- |
| `year` | midterm election year |
| `president` | name of president |
| `party` | Democrat or Republican |
| `approval` | Gallup approval rating at midterms |
| `seat.change` | change in the number of House seat's for the president's party |
| `rdi.change` | change in real disposable income over the year before |

---

## Scenario

Imagine we are in 2018 just *before* the US mid-term election. So for the 2018 observation,

- .content-box-green[`president`] is known (Trump);
- .content-box-green[`party`] is known (Republican);
- .content-box-green[`approval`] is known;
- .content-box-green[`rdi.change`] is known; but
- .content-box-red[`seat.change`] is **unknown**, since it is about a **future** event... Yet we could predict it :-)


.footnote[[1] Slides adapted from http://www.mattblackwell.org/files/teaching/gov50/regression-ii.pdf]


---




``` r
midterms &lt;- read.csv("midterms.csv")
```

The top of the table...


| year|president  |party | approval| seat.change| rdi.change|
|----:|:----------|:-----|--------:|-----------:|----------:|
| 1946|Truman     |D     |       33|         -55|         NA|
| 1950|Truman     |D     |       39|         -29|        8.2|
| 1954|Eisenhower |R     |       61|          -4|        1.0|
| 1958|Eisenhower |R     |       57|         -47|        1.1|
| 1962|Kennedy    |D     |       61|          -4|        5.0|

... and the bottom of the table.


| year|president |party | approval| seat.change| rdi.change|
|----:|:---------|:-----|--------:|-----------:|----------:|
| 2010|Obama     |D     |       45|         -63|        3.5|
| 2014|Obama     |D     |       40|         -13|        4.6|
| 2018|Trump     |R     |       38|          NA|        4.1|

---

## Simple regression

$$ \widehat{seat.change} = \hat{\alpha} + \hat{\beta} \times approval $$


``` r
fit_simple &lt;- 
  lm(formula = seat.change ~ approval, 
     data = midterms)
```

.content-box-yellow[

Remember: the attribute `formula` is constructed as `outcome ~ predictor`.

]

--

### How do you geta summary of the results from `lm()`?

- For example, you can use `summary()` (but there are many other functions you could use...)

---


``` r
summary(fit_simple)
```

```
## 
## Call:
## lm(formula = seat.change ~ approval, data = midterms)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -31.348 -10.913   6.091  11.473  26.867 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -96.8448    21.2569  -4.556 0.000324 ***
## approval      1.4244     0.4094   3.479 0.003096 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 17.41 on 16 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.4307,	Adjusted R-squared:  0.3951 
## F-statistic: 12.11 on 1 and 16 DF,  p-value: 0.003096
```

--
.small[
So far, we discussed .content-box-yellow["Estimate"], which is the coefficient for each independent variable ( `\(\hat{\beta}_j\)`) and the intercept ( `\(\hat{\alpha}\)` ) and the .content-box-yellow["Multiple R-squared"], which is the proportion of the variation in `\(Y\)` explained by the model.
]
---

## Mutliple regression

Using the `formula` syntax `outcome ~ predictor_1 + predictor_2 + ...` we can add additional predictors (i.e independent variables).


``` r
fit_multi &lt;- 
  lm(formula = seat.change ~ approval + rdi.change, 
     data = midterms)
```

---

&lt;div style = 'font-size: 14pt'&gt;


``` r
summary(fit_multi)
```

```
## 
## Call:
## lm(formula = seat.change ~ approval + rdi.change, data = midterms)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -28.793 -13.405   2.787  10.407  29.218 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept) -120.4363    30.2634  -3.980  0.00137 **
## approval       1.5720     0.4739   3.317  0.00509 **
## rdi.change     3.3342     2.2755   1.465  0.16495   
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 17.27 on 14 degrees of freedom
##   (2 observations deleted due to missingness)
## Multiple R-squared:  0.4448,	Adjusted R-squared:  0.3655 
## F-statistic: 5.609 on 2 and 14 DF,  p-value: 0.01625
```

&lt;/div&gt;
The only difference here is that we have an extra row for the additional predictors. The interpretation of the .content-box-yellow["Estimate"] now is variation in `\(\hat{Y}\)` ( i.e. `\(\Delta\hat{Y}\)` ) when variation in `\(X_j\)` is 1 ( i.e. `\(\Delta X_j=1\)` ) and when other variables are held constant.

---

## Using predict()

If we don't pass new data, the function `predict()` will just return the prediction for `\(Y\)` (i.e. `\(\hat{Y}\)` ) for each observation in our original data.


``` r
predict(fit_multi)
```

```
##          2          3          4          5          6          7          8 
## -31.786520 -21.207962 -27.162685  -7.871170 -33.595516  -7.252560 -14.207542 
##          9         10         11         12         13         14         15 
## -17.733263 -38.406687  -4.393679 -10.586758 -35.119322   1.989527 -12.729174 
##         16         17         18 
## -41.694051 -38.025037 -42.217598
```

.small[
The number you see above the prediction is the row number of your `midterms` data (which is replaced by labels if your rows are named). Note that the first and last rows are (of course!) missing because the `seat.change` is missing.
]


``` r
midterms[1,]
```

```
##   year president party approval seat.change rdi.change
## 1 1946    Truman     D       33         -55         NA
```

---

## Predict based on your data

But we don't need to use the original data for our predictions. Remember that `lm()` gives us a continuous straight line; we can predict `\(Y\)` for any value of each `\(X_j\)`. 

For example, let's get `\(\widehat{seat.change}\)` using our simple model for an approval rate of 20% and 80% (which is not in the original data set).


``` r
*my_new_data &lt;-
* data.frame(approval = c(20, 80)) # Create new data

predict(fit_simple, 
*       newdata = my_new_data) # Pass the new data to predict()
```

```
##         1         2 
## -68.35610  17.10995
```

With an approval rate of .content-box-green[**20**] the president's party is predicted to lose .content-box-purple[**68**] seats and with an approval rate of .content-box-green[**80**] to gain .content-box-purple[**17**] seats.

---

## How confident are we in our prediction?

To obtain the 95% confidence intervals (more on this next week) around our predicted values ( `\(\hat{Y}\)` ), we can add `interval = "confidence"`.


``` r
*seat.change_prediction &lt;- # Storing prediction
  predict(fit_simple, 
          newdata = my_new_data, 
*         interval = "confidence") # Adding confidence interval
seat.change_prediction 
```

```
##         fit       lwr       upr
## 1 -68.35610 -96.58698 -40.12522
## 2  17.10995  -9.56615  43.78605
```

---

# Which we can then plot... 


``` r
# First we need to create a data.frame adding the `approval` rate
# that we want to use as input values
data.frame(seat.change_prediction,
           approval = c(20, 80)) |&gt;
# Then we plot  
  ggplot(aes(y = fit, 
             ymin = lwr, ymax = upr, 
             x = approval)) +
  geom_point() +
  geom_errorbar() +
  labs(y = "seat.change")
```

&lt;img src="week-07_files/figure-html/unnamed-chunk-14-1.svg" width="30%" style="display: block; margin: auto;" /&gt;

---

## Let's compare our predictions with the actual results ... 

- We are in 2018, just before the mid-term. (Trump is president).

- We want to use `approval` to predict the outcome of the upcoming midterm election for Trump's party (i.e., `\(\widehat{seat.change}\)`). 

- Note that the 2018-Trump row was not used to estimate the model because of the missing value (of course, we are before the mid-term).

- We only know that Trump's approval rate in 2018 was .content-box-green[**38%**]. So we can plug that value in...

--


``` r
predict(fit_simple, newdata = data.frame(approval = 38))
```

```
##         1 
## -42.71629
```

We predict that in the 2018 mid-term his party will lose about .content-box-purple[**43**] seats.

---

## Does adding predictors improve the accuracy of our model?

This is out multivariate regression model: in addition to `approval` we are also using `rdi.change` (change in real disposable income over the year before, an economic measure)


``` r
fit_multi &lt;- 
  lm(formula = seat.change ~ approval + rdi.change, 
     data = midterms)
```



``` r
fit_multi
```

```
## 
## Call:
## lm(formula = seat.change ~ approval + rdi.change, data = midterms)
## 
## Coefficients:
## (Intercept)     approval   rdi.change  
##    -120.436        1.572        3.334
```

---

## Now, let's predict using our fit_multi...


``` r
predict(fit_multi, 
        newdata = data.frame(approval = 38,
*                            rdi.change = 4.1)) # Observed value
```

```
##         1 
## -47.02877
```

Using the multiple regression model, we predict his party will lose .content-box-purple[**47**] seats instead of about .content-box-purple[**43**] seats with the simple regression model.

## Which model did better?

### Let's check Wikipedia!

---

&lt;iframe id="wiki" src="https://en.wikipedia.org/wiki/2018_United_States_elections" width = '900px' height = '600px'&gt;&lt;/iframe&gt;

---

.content-box-yellow[

Adding extra an variable in this case **decreased** the accuracy of the model!

]

.content-box-red[

The substantial interpretation here is that the national economy does not explain voting behaviour as much as we think...

]



### How could we have known better?

We could have checked the .content-box-yellow[**"Adjusted R-squared"**] of the two models...

The .content-box-yellow[**""Multiple R-squared"**], the `\(R^2\)` we saw last week, explains the variation in the outcome variable that is explained by the predictors. Yet, the multiple R-squared will **always** increase if we add new predictors. So it is useless to compare models after adding an extra predictors...

This is why it is more appropriate to compare the .content-box-yellow[**"Adjusted R-squared"**] when we add new predictors. 

---


``` r
summary(fit_simple)
```

```
## 
## Call:
## lm(formula = seat.change ~ approval, data = midterms)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -31.348 -10.913   6.091  11.473  26.867 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -96.8448    21.2569  -4.556 0.000324 ***
## approval      1.4244     0.4094   3.479 0.003096 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 17.41 on 16 degrees of freedom
##   (1 observation deleted due to missingness)
## Multiple R-squared:  0.4307,	Adjusted R-squared:  0.3951 
## F-statistic: 12.11 on 1 and 16 DF,  p-value: 0.003096
```

---


``` r
summary(fit_multi)
```

```
## 
## Call:
## lm(formula = seat.change ~ approval + rdi.change, data = midterms)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -28.793 -13.405   2.787  10.407  29.218 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept) -120.4363    30.2634  -3.980  0.00137 **
## approval       1.5720     0.4739   3.317  0.00509 **
## rdi.change     3.3342     2.2755   1.465  0.16495   
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 17.27 on 14 degrees of freedom
##   (2 observations deleted due to missingness)
## Multiple R-squared:  0.4448,	Adjusted R-squared:  0.3655 
## F-statistic: 5.609 on 2 and 14 DF,  p-value: 0.01625
```

---
class: inverse, center, middle

# Individual in-class quiz/tutorial (Part 1, until `predict()` included)

<div class="countdown" id="timer_8271c177" data-update-every="1" tabindex="0" style="right:0;bottom:0;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">10</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
class: inverse, center, middle


Prof. Llaudet slides on Probability


---
class: inverse, center, middle

# Individual in-class quiz/tutorial (Part 2)

<div class="countdown" id="timer_29be8ef0" data-update-every="1" tabindex="0" style="right:0;bottom:0;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">10</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
class: inverse, center, middle

# Group in-class problem set

---
class: inverse, center, middle

# Attendance

---
class: inverse, center, middle

# See you next week with Uncertainty (and p-values)!

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="assets/remark-zoom.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "4:3",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
