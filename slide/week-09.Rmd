---
title: "SSPS [4102|6006] Data Analytics</br>[in the Social Sciences|for Social Research]"
subtitle: "Week 09</br>Machine learning"
author: "Francesco Bailo"
date: "Semester 1, 2025 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    css: ["default", "assets/sydney-fonts.css", "assets/sydney.css"]
    self_contained: false # if true, fonts will be stored locally
    seal: true # show a title slide with YAML information
    includes:
      in_header: "assets/mathjax-equation-numbers.html"
    nature:
      beforeInit: ["assets/remark-zoom.js", "https://platform.twitter.com/widgets.js"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '4:3' # alternatives '16:9' or '4:3' or others e.g. 13:9
      navigation:
        scroll: false # disable slide transitions by scrolling

---

background-image: url('assets/USydLogo.svg')
background-size: 95%

<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>

```{r setup, include=FALSE}

options(htmltools.dir.version = FALSE)

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
                      dev = 'svg', 
                      fig.width = 4, 
                      fig.height = 4, out.width="30%",
                      fig.align="center")

library(knitr)
library(kableExtra)
library(tidyverse)
library(sf)
library(DiagrammeR)
library(cowplot)
library(gapminder)
library(ggrepel)

ggplot2::theme_set(theme_bw())

```

---

## Acknowledgement of Country

I would like to acknowledge the Traditional Owners of Australia and recognise their continuing connection to land, water and culture. The  University of Sydney is located on the land of the Gadigal people  of the Eora Nation. I pay my respects to their Elders, past and present.
---

## Recap from last week

- Hypothesis Testing Intuition
  - Null Hypothesis
  - Alternative Hypothesis
  - Test Statistic
  - P-Values
- Hypothesis Testing Formal Procedure (using `lm()` in R)

---

## Today's class

| Time        | Content                         |
|-------------|---------------------------------|
| 14:00-14:40 | Machine learning                |
| 14:40-15:00 | Lab: k-NN                       |
| 15:00-15:15 | Individual quiz/tutorial Part 1 |
| 15:15-15:30 | Lab: linear regression (again!) |
| 15:30-15:45 | Individual ex. with peer-review |
| 15:45-16:00 | Lab: logistic regression        |
| 16:00-16:10 | Individual quiz/tutorial Part 2 |
| 16:10-17:00 | Group in-class problem set      |


---
class: inverse, center, middle

# Closing the loop on Week 08 qualitative feedback


---

## üëç What You Liked

- Clear explanations, well-structured unit  
- Individual quizzes and activities are helpful  
- ChatGPT support is very useful  
- Felt supported and encouraged to ask questions  
- Enjoyed learning and applying R  
- Real-world data and case studies made learning engaging  
- Fun, hands-on assessments and in-class tasks  

---

## üëé What Students Found Challenging

- Assignment 1 was too hard and too heavily weighted (40%)  
- Needed coding skills earlier‚Äîtaught too close to deadline  
- Lack of detailed guidance for major tasks  
- 3-hour classes caused fatigue and attention drop  
- Content sometimes moved too fast to follow  
- Wanted more foundational coding instruction  
- Too much early focus on theory, not enough on R  


---

class: inverse, center, middle

# Machine Learning

<iframe src="https://giphy.com/embed/IZY2SE2JmPgFG" width="480" height="274" style="" frameBorder="0" class="giphy-embed" allowFullScreen></iframe>

.footnote[Slides adapted from *Machine learning with R* by Brett Lantz (2023)]


---

## What is Machine Learning?

### Definition

.content-box-yellow[

Machine learning is the study of 

- [1] **computer algorithms** that allow 

- [2] **systems** to 

- [3] **learn from data** and 

- [4] **make decisions** without explicit programming.
]

- **Common Misconceptions**: Not all machine learning leads to AI; most applications are task-specific.

- **Real-World Role**: Helps transform raw data into actionable insights.

---

## The Origins of Machine Learning

- **Historical Context**: Machine learning grew from advances in 

  - computing power, 
  - data availability, and 
  - statistical methods.
  
- **Evolution**: The field has continuously evolved as new data and more powerful computational resources became available.

- **Relationship to AI**: Machine learning is a core component of AI, but AI also encompasses broader goals, including replicating human cognition.

---

## The Cycle of Advancement

- **Data, Methods, and Computing Power**: A loop where increased data drives the development of new methods and computational needs.
- **Impact**: Enables larger, more complex datasets to be analysed, spurring new discoveries and capabilities in machine learning.

```{r echo = FALSE, out.width='100%'}
# Load necessary library
library(DiagrammeR)

grViz("
  digraph {
    graph [layout = circo]

    # Define nodes
    A [label = 'Available Data', shape = circle, style = filled, fillcolor = lightgray]
    B [label = 'Statistical Methods', shape = circle, style = filled, fillcolor = lightgray]
    C [label = 'Computing Power', shape = circle, style = filled, fillcolor = lightgray]

    # Define edges
    A -> B
    B -> A
    B -> C
    C -> B
    C -> A
    A -> C
  }
")
```


---

## Machine Learning vs. Data Mining

- **Data Mining**: Focuses on finding patterns within large datasets that humans use to solve problems.

- **Machine Learning**: More focused on teaching computers to solve problems independently through data analysis.

- **Overlap**: Both fields use similar techniques but differ in application focus.

---

## Machine Learning vs. AI vs. Traditional Statistics

|                             | Traditional Statistics      | Machine Learning                  | Artificial Intelligence       |
|-----------------------------|------------------------------------|-------------------------------|-------------------------------|
| **Application**             | Hypothesis testing and insight    | Prediction and knowledge generation | Automation                  |
| **Success Criterion**       | Greater understanding             | Ability to intervene before things happen | Efficiency and cost savings |
| **Success Metric**          | Statistical significance          | Trustworthiness of predictions | Return on investment (ROI)  |
| **Input Data Size**         | Smaller data                      | Medium data                   | Bigger data                  |
| **Implementation**          | Reports and presentations for knowledge sharing | Scoring databases or interventions in business practices | Custom applications and automated processes |



---

## Machine Learning vs. AI vs. Traditional Statistics

- **Machine Learning**: Focuses on prediction and pattern recognition.
- **AI**: Aims for automation and human-like decision-making capabilities.
- **Traditional Statistics**: Emphasizes hypothesis testing and deriving insights from data.
- **Key Differences**: Input size, application goals, and the degree of automation.

.content-box-yellow[

- Traditional statistics (or what we covered so far)

$$\text{non-statistical theory} \rightarrow model \rightarrow insights$$
- Machine learning

$$\text{statistical theory} \rightarrow model \rightarrow predictions$$

]

---

## Uses of Machine Learning

- **Examples**:
  - Email spam detection.
  - Predictive maintenance in manufacturing.
  - Fraud detection in finance.
  - Personalized recommendations in e-commerce.
  
  - But also, predicting atrocity and genocide<sup>1</sup>.
  
- **Success Criteria**: 

1. Accuracy, 
2. efficiency, and 
3. scalability.

.footnote[[1] Goldsmith, B. E., Butcher, C. R., Semenovich, D., & Sowmya, A. (2013). Forecasting the onset of genocide and politicide: Annual out-of-sample forecasts on a global dataset, 1988‚Äì2003. *Journal of Peace Research*, 50(4), 437‚Äì452. https://doi.org/10.1177/0022343313484167
]

---

## Machine Learning‚Äôs Ethical Challenges

### Potential Harms: Unintended consequences like perpetuating biases or privacy violations.

**Case 1: Amazon's AI recruiting tool exhibited gender bias**:<sup>1</sup> Amazon developed an AI-based recruiting tool to automate resume screening, but it showed a preference for male candidates due to biased training data predominantly sourced from male applicants. The system penalised resumes that included terms like "women's" or references to women‚Äôs colleges, highlighting the pitfalls of biased training data in machine learning models.


.footnote[[1] Dastin, J. (2018, October 10). Amazon scraps secret AI recruiting tool that showed bias against women. *Reuters*. https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G
]

---

## Machine Learning‚Äôs Ethical Challenges

### Using Machine learning in weapon systems

**Case 2: ML-Driven Targeting in Warfare** The Israeli military has allegedly<sup>1</sup> developed a ML (maybe AI?) system called ‚ÄúLavender‚Äù that identifies potential targets for airstrikes in Gaza, marking tens of thousands of individuals, including many civilians, as suspects for assassination with minimal human oversight. The AI‚Äôs decisions were often treated as final, resulting in high casualty rates.

**Lack of Human Oversight and High Civilian Casualties**: The system was used with minimal checks, often targeting individuals in their homes with their families present, leading to significant collateral damage. Human oversight was reduced to a cursory check, sometimes taking only seconds, and errors in the AI‚Äôs judgment frequently led to the deaths of uninvolved civilians.

.footnote[[1] Iraqi, A. (2024, April 3). ‚ÄòLavender‚Äô: The AI machine directing Israel‚Äôs bombing spree in Gaza. *+972 Magazine*. https://www.972mag.com/lavender-ai-israeli-army-gaza/]

---

## Machine Learning Success Stories

- **Key Successes**:
  - Medical diagnostics aiding doctors in detecting diseases early.
  - Autonomous driving systems in vehicles.
  - Climate prediction models forecasting weather and environmental changes.
  
- **Augmentation vs. Replacement**: In general, ML works best when augmenting human expertise and not replacing it.

---

## Limits of Machine Learning

- **Algorithmic Limitations**: 

  - Limited flexibility, 
  - context understanding, and
  - lack of common sense.
  
- **Reality Check**: Machine learning is powerful but not infallible.

---

## The Double-Edged Sword

- **Potential**: Machine learning offers immense benefits when carefully directed and ethically applied.

- **Risks**: Unchecked use can lead to automation of harmful biases or unethical outcomes.

- **Future Directions**: Continuous oversight, ethical considerations, and careful application are essential.

---

class: inverse, center, middle

# How Machines Learn

---

## How Machines Learn


- **Learning from Data:**
  - Machines learn by identifying patterns in data and using these patterns to make predictions or decisions.
  
- **Key Elements:**
  - **Data Input:** Data is fed into the system.
  - **Learning Algorithm:** The core method that finds patterns in the data.
  - **Model Output:** The algorithm produces a model that can make predictions or classifications based on new data.

---

## How Machines Learn

.center[<img src = '../img/brett-2023-01.png'></img>]

.footnote[(Lantz, 2023, p. 15)]

---

## Abstraction and Generalisation

.center[<img src = '../img/brett-2023-01.png' width = '60%'></img>]

- **Abstraction:**
  - The process of simplifying complex problems by focusing on essential details while ignoring irrelevant information.
  - Helps the model understand underlying patterns rather than memorizing specific instances.
- **Generalisation:**
  - The ability of a machine learning model to perform well on unseen data.
  - A model that generalizes well can apply what it has learned from the training data to make accurate predictions on new, unseen data.

---

## Evaluation

.center[<img src = '../img/brett-2023-01.png' width = '60%'></img>]

- **Evaluating Model Performance:**
  - Essential to ensure that the model is not just fitting the training data but also performing well on new data.
- **Common Evaluation Metrics:**
  - **Accuracy:** Measures how often the model makes correct predictions.
  - **Precision and Recall:** Important for tasks with imbalanced classes.
  - **Cross-Validation:** A method to test the model‚Äôs performance using multiple subsets of the data to avoid overfitting.

---

## Types of Machine Learning Algorithms

- **Supervised Learning:**
  - Algorithms learn from labeled data and make predictions based on it (e.g., regression, classification).
- **Unsupervised Learning:**
  - Algorithms find hidden patterns or intrinsic structures in input data without labeled responses (e.g., clustering, association).
- **Reinforcement Learning:**
  - Algorithms learn by interacting with an environment and receiving feedback (rewards or punishments) to achieve a goal (e.g., robotics, game AI).

---

## Classification vs. Numerical Prediction

.pull-left[

**Classification:**
- **Definition:** A type of predictive modeling task where the output variable is a category or label.
- **Purpose:** Assigns input data to predefined classes or groups.
- **Examples:**
  - Email spam detection (spam vs. not spam).
  - Diagnosing a disease (disease vs. no disease).
- **Algorithms Used:** K-Nearest Neighbors, Logistic Regression.
]

.pull-right[

**Numerical Prediction:**
- **Definition:** A type of predictive modelling where the output variable is a continuous numerical value.
- **Purpose:** Predicts numerical outcomes based on input features.
- **Examples:**
  - Forecasting house prices.
  - Predicting stock prices or sales figures.
- **Algorithms Used:** Linear Regression.
  
]

- **Key Difference:**
  - **Classification** deals with categorizing data into discrete labels.
  - **Numerical Prediction** involves predicting continuous quantities.
  
---

class: inverse, center, middle

# R LAB

### Numeric prediction of continuous outcome: Linear regression (`lm()`)
### Classification for binary outcome: Logistic regression: (`glm(family = "binomial")`)
### Classification for categorical outcome: k-Nearest Neighbors (k-NN)
  
---

class: inverse, center, middle

# Numeric prediction of continuous outcome: Linear regression (`lm()`)

---

class: inverse, center, middle

# Classification for binary outcome: Logistic regression: (`glm(family = "binomial")`)

---

class: inverse, center, middle

# Classification for categorical outcome: k-Nearest Neighbors (k-NN) (`knn()`)


---

## Introduction to Lazy Learning

- **What is Lazy Learning?**
  - Lazy learning algorithms delay processing until a query is made to the system.
  - They do not create a model during training but use the training data directly for prediction.
- **Key Characteristics:**
  - Minimal training time, but more computation is required during prediction.
  - Examples include k-Nearest Neighbours (k-NN).

---

## k-Nearest Neighbors (k-NN) Overview

- **What is k-NN?**
  - A simple, instance-based learning algorithm that classifies data points based on the classes of their nearest neighbors.
  - **k** represents the number of nearest neighbours considered in the decision.
- **How it Works:**
  - Finds the k closest training examples to the new data point.
  - Classifies the new data point based on the majority class of its neighbours.
  

---

### Food data

```{r}
food_data <- 
  data <- data.frame(
    Ingredient = c("Apple", "Bacon", "Banana", "Carrot", "Celery", 
                   "Lettuce", "Cucumber", "Green Bean", "Nuts", 
                   "Shrimp", "Fish", "Cheese", "Pear", "Grape", 
                   "Orange"),
    Sweetness = c(10, 1, 10, 7, 3, 2, 3, 3, 2, 2, 1, 1, 9, 9, 8),
    Crunchiness = c(9, 4, 1, 10, 10, 9, 8, 6, 6, 4, 3, 2, 6, 2, 2),
    Food_type = c("Fruit", "Protein", "Fruit", "Vegetable", "Vegetable", 
                  "Vegetable", "Vegetable", "Vegetable", "Protein", 
                  "Protein", "Protein", "Protein", "Fruit", "Fruit", 
                  "Fruit")
  )

head(food_data)
```

---

### Food data, no missing the type!

```{r}
food_unknown <- 
  data.frame(Ingredient =  "Tomato",
             Sweetness = 6,
             Crunchiness = 4,
             Food_type = "unknown")
head(food_unknown)
```

---

### Let's plot

```{r out.width="80%", fig.width=6, fig.height=4}
dplyr::bind_rows(food_data, food_unknown) |>
  ggplot(aes(x=Sweetness, y=Crunchiness)) + 
  geom_point(aes(color=Food_type), size = 5) +
  ggrepel::geom_text_repel(aes(label=Ingredient))
```

---

### Let's classify

### Classification problem: What type of food is tomato?

Note: I have three possible types (i.e., classes): Fruit, Protein, Vegetable

```{r}
library(class)
pred <- 
  class::knn(train = dplyr::select(food_data, Sweetness, Crunchiness),
             test = dplyr::select(food_unknown, Sweetness, Crunchiness),
             cl = food_data$Food_type, # true classification
             k=3) # number of neighbours considered
```

And our prediction or classification for tomato is ...

--

```{r}
pred
```


---

### Of course, this was a toy example. 

- I can train my k-NN classifier using more than just two dimensions. In fact, ML models tend to have a very large number of dimensions.

- I can use my k-NN classifier for more than just three classes. 

---

### So, why is the k-NN Algorithm Lazy?

#### Lazy Learning Defined:
- k-NN is considered a lazy learning algorithm because it skips the **abstraction** and **generalization** processes typically involved in learning.
- No model is built during training; instead, it stores the training data verbatim.
- **Training Phase:**
  - Fast because no actual training occurs‚Äîjust storing data.
- **Prediction Phase:**
  - Slow because it relies heavily on comparing new data to all stored instances.

#### Instance-Based Learning:
- Also known as rote learning, k-NN is **non-parametric**, meaning it does not learn parameters or generate theories about the data.
  
---

## Non-Parametric Nature of k-NN

- **Non-Parametric Learning:**
  - No assumptions about the data distribution are made, allowing the learner to find natural patterns in the data.
  - Unlike parametric methods, it does not create an abstracted model that could introduce biases.

- **Limitations and Strengths:**
  - **Limitations:** 
    - Lack of model makes it difficult to understand how decisions are made - there is no coefficient (i.e. parameter) to interpret.
  - **Strengths:** 
    - Can still make useful predictions without needing to fit the data into a specific model.
    - **Powerful in applications where the focus is on pattern recognition over model interpretation**.
    
---

## Parametric Models instead...

.small[

- **Parametric Models:**
  - **Definition:** Models that make assumptions about the data‚Äôs underlying structure and learn parameters during training.
  - **Example: Linear Regression**
    - Assumes a linear relationship between input variables (features) and the output (target).
    - **Parameters Learned:** Coefficients (slopes) $\hat\beta$ and intercept $\hat\alpha$ that define the best-fit line.
    - **Advantages:**
      - Simple and fast; easy to interpret and understand.
      - Efficient with smaller datasets since it simplifies the data into a defined form.
    - **Limitations:**
      - Struggles with complex patterns that don't fit the assumed structure (e.g., non-linear relationships).

]

---

## Let's try  k-NN on a more interesting problem using the AES 2022 data

### Is it possible to predict party affiliation from 

1. Age
2. Gender (as binary)
3. Years in tertiary education
4. Left-right leaning (on 1-to-10 scale)
5. Opinion on degree of government efforts to make people's incomes more equal (on a 1-to-10 scale)

Remember: k-NN classifies a categorical outcome BUT only works with continuous variables or variables that can be treated as continuous (e.g., Likert-scale) because k-NN uses a **distance function**.

---

### 0. Let's load the data selecting only the variables I need (I also rename the variable)

```{r}
library(haven)
library(tidyverse)
aes22_raw <- 
  haven::read_sav("../data/aes22_unrestricted_v2.sav") |>
  dplyr::select(party = B1, age = AGE, gender = H1, 
                edu = G2, lr = B8_1, equal = D12)
```

#### 1. Parties as factors, not numbers

```{r}
aes22_raw$party <- haven::as_factor(aes22_raw$party)
```
 
- I use the function `haven::as_factor` to convert labelled values into character values. This will make interpreting the results easier.

---

#### 2. Now some recoding to label missing values of numerical variables correctly as NA

```{r}
aes22_recoded <-
  aes22_raw |>
  dplyr::mutate(age = ifelse(age==999, NA, age),
                gender = ifelse(gender==999, NA, gender),
                edu = ifelse(edu==999, NA, edu),
                lr = ifelse(lr==999, NA, lr),
                equal = ifelse(equal==999, NA, equal))
```

---

#### 3. Some more recoding for the `party` variable (which is now a factor variable, with labels instead of numebers)

I have other responses that I want to set as `NA`

- I don't know how to interpret these responses within a party list, so I just consider them as missing.

```{r eval = FALSE}
aes22_recoded <- 
  aes22_recoded |>
  dplyr::mutate(party = 
                  dplyr::case_when(party == "Swing Voter" ~ NA, 
                                   party == "No party" ~ NA,
                                   party == "Item skipped" ~ NA, 
                                   party == "Other party (not specified)" ~ NA, 
                                   party == "Does not apply" ~ NA, 
                                   party == "Item skipped" ~ NA, 
                                   TRUE ~ party))
```

---

### This is the summary of all the variable in my data after the recoding

```{r}
summary(aes22_recoded)
```

---

#### 4. I still need to deal with `gender`. 

- The variable can take three values (1 = "Male", 2 = "Female" or 3 = "Other").
1. First, I need a continuous (or binary) binary variable. But as it is now, it doesn't make any sense as a continuous variable. "Other" is not an "higher" value than "Male" or "Female" and "Female" is not equally placed on a continuous scale between "Male" and "Other". 
2. I can't use categorical variables with k-NN (remember: I must measure the distance between my observations!)

Let's create a new binary variable `female` and set "male" to `0`, "female" to `1` and "Other" to `NA`.

```{r}
aes22_recoded <- 
  aes22_recoded |>
  dplyr::mutate(female = dplyr::case_when(gender == 1 ~ 0,
                                          gender == 2 ~ 1)) 
# All values not explicitly mentioned are set to `NA` by default
```

---

### And the resulting data

```{r}
summary(aes22_recoded)
```


---

### Let's now predict `party` using the other variables!

#### 5. Let's drop all the missing values (`NA`) using `drop_na()` 

- `knn` does like any missing value in your data

```{r}
aes22_recoded_no_na <-
  aes22_recoded |>
  tidyr::drop_na()
```

- How many observations we are left with?

```{r}
nrow(aes22_recoded_no_na)
```


---

#### 6. Let's create a "train" and a "test" dataset.

- Remember, ML algorithms are trained on some data and then their accuracy if measured on some test data.

- We must then split our data into two, a train dataset and a test dataset.

- We must make sure that observations are **randomly** assigned to train and test.

#### 6.1 Let's shuffle the order of the dataset using `sample()` (because it might be ordered on something...)

```{r}
aes22_recoded_no_na <- aes22_recoded_no_na[sample(1815),]
```

- `sample()` will return any vector in a random order!

```{r}
sample(c("A", "B", "C"))
```

---

#### 6.2 Let's create train and test

Since we have 1815 observations (and $\frac{1815}{2} \approx 907$), we do...

```{r}
aes22_train <- 
  aes22_recoded_no_na[1:907,]
```

and 

```{r}
aes22_test <- 
  aes22_recoded_no_na[908:1815,]
```


---

#### 7. Let's train and test using k-nearest neighbour classification (`knn()`)


```{r}
pred <- 
  class::knn(train = dplyr::select(aes22_train, female, age, edu, lr, equal),
             test = dplyr::select(aes22_test, female, age, edu, lr, equal),
             cl = aes22_train$party,
             k = 5) # You can vary this
```

#### 8. How accurate it is?

Remember $$accuracy = \frac{\text{correct predictions}}{\text{number of predictions}}$$

```{r}
sum(pred == aes22_test$party) / nrow(aes22_test)
```

Not great, but also not too bad since we are classifying over `r length(unique(aes22_test$party))` different parties!

---

#### 9. Let's focus on predicting only the four major parties

```{r}
aes22_recoded_major_parties <-
  aes22_recoded_no_na |> dplyr::filter(party %in% c("Labor","Liberal","Greens", "National Party"))
nrow(aes22_recoded_major_parties)
aes22_train <- aes22_recoded_major_parties[1:750,]
aes22_test <- aes22_recoded_major_parties[751:1500,]
```

```{r}
pred <- 
  class::knn(train = dplyr::select(aes22_train, female, age, edu, lr, equal),
             test = dplyr::select(aes22_test, female, age, edu, lr, equal),
             cl = aes22_train$party, k = 5)
sum(pred == aes22_test$party) / nrow(aes22_test)
```


---

#### And here our confusion matrix

```{r}
table(`true value` = as.character(aes22_test$party), 
      `prediction` = as.character(pred))
```

- With proportional values

```{r}
prop.table(table(`true value` = as.character(aes22_test$party), 
                 `prediction` = as.character(pred)), 
           margin = 1) # margin = 1 indicates rows, 
                      # i.e. sum of rows is 100%
```

---

#### 10. Let's focus on predicting only the two major parties

```{r}
aes22_recoded_major_parties <-
  aes22_recoded_no_na |> dplyr::filter(party %in% c("Labor","Liberal"))
nrow(aes22_recoded_major_parties)
aes22_train <- aes22_recoded_major_parties[1:628,]
aes22_test <- aes22_recoded_major_parties[629:1257,]
```

```{r}
pred <- 
  class::knn(train = dplyr::select(aes22_train, female, age, edu, lr, equal),
             test = dplyr::select(aes22_test, female, age, edu, lr, equal),
             cl = aes22_train$party, k = 5)
sum(pred == aes22_test$party) / nrow(aes22_test)
```


---

#### And here our confusion matrix

```{r}
table(`true value` = as.character(aes22_test$party), 
      `prediction` = as.character(pred))
```

- With proportional values

```{r}
prop.table(table(`true value` = as.character(aes22_test$party), 
                 `prediction` = as.character(pred)), 
           margin = 1) # margin = 1 indicates rows, 
                      # i.e. sum of rows is 100%
```


---
class: inverse, center, middle

# Individual quiz/tutorial Part 1

```{r echo = FALSE}
library(countdown)

countdown(minutes = 15, seconds = 00)
```

---

# After a non-parametric model (k-NN), let's check a parametric model instead... 

# The linear regression!

---

## If k-NN can be used to predict multiple classes (e.g., parties), the linear regression is used to predict a continuous variable. 

#### Using the AES 2022 dataset, let's predict respondent's left-right position using the variables we already recoded.

Note: `lm()` will automatically drop records with missing values, so `drop_na()` is not technically required

```{r}
head(aes22_recoded)
```

---

#### 1. Since, the data has been already cleaned and prepared, I can run `lm()`

```{r}
fit <- lm(lr ~ factor(gender) + edu + equal, data = aes22_recoded)
```

- Wait a minute, why don't we use the binary variable `female` and instead we use `factor(gender)`? 

- `lm()` requires a **numeric** outcome variable, but it can take **categorical** as well **numeric** predictors. 

.content-box-yellow[

- Importantly, here `gender` should not be treated as numeric since its values are not to be intended as values on a continuous scale! The value `3` = 'Other'  does not inherently represent a value three times larger than `1` = "Male". So we must treat it as a `factor()`, or categorical variable. 

]

---

#### 2. Let's check the coefficients (or the parameters of this model) and their statistical significance

```{r}
summary(fit)
```

---

#### 3. How do we interpret our model summary stats and the model parameters (coefficients)?

1. $R^2: 0.2013$. This means that 80% of the variation in the dependent variable `lr` is .content-box-purple[**NOT**] explained/predicted from the independent variables of the model.
2. Being a female .content-box-purple[**instead**] of a male, (`gender` = 2) is statistically associated with being more left-wing (by .57 on the 0-to-10 scale of the DV).
3. Being other instead of a male (remember in the case of categorical IV, compare with the base level!), is associated with being more left-wing but this association is not statistically significant.
4. For every extra year in tertiary education, Australian voters are expected to move left-wing by .06, and this association is statistically significant.
5. For each extra point on the `equal` scale, Australian voters are expected to move right-wing by .33 on the `lr` scale.

---

#### 4. Can we predict where an Australian woman does identify on average on the left-right scale for number of years in teritiry education?

Let's first check the distribution of the variables

```{r}
summary(aes22_recoded)
```

---

... then, let's predict while setting `equal` to 5, the median of the sample and `gender` to 2.

```{r}
pred <- 
  predict(fit, newdata = data.frame(gender = 2, edu = 0:10, equal = 5))
```

```{r}
pred
```

- The average woman with 0 years of tertiary education and the median opinion on the `equal` question (i.e. 5) is expected to be slightly on the left-hand side of the spectrum (4.83, with 5 being the mid value).

- As the average woman gets to spend more time on her tertiary education, she expected to move left-wing (note that this is a linear regression, so everything will change linearly!).

---

#### 5. What about Australian men?


```{r}
pred <- 
  predict(fit, newdata = data.frame(gender = 1, edu = 0:10, equal = 5))
```

```{r}
pred
```

- On average an Australian men with a median opinion on `equal`, will move to the left-hand side of the spectrum only after six years of tertiary education. 

---
class: inverse, center, middle

# Individual exercise with peer-review

# Reading a regression table

```{r echo = FALSE}
library(countdown)

countdown(minutes = 5, seconds = 00)
```

---
class: inverse, center, middle

### What we do when the outcome variable is binary (e.g., what does predict if voter is a female)?

# The Logistic Regression

---

## Introduction to Logistic Regression

- **What is Logistic Regression?**
  - A statistical model used for binary classification problems (e.g., yes/no, success/failure).
  - Unlike k-NN and linear regression, logistic regression predicts the probability of an outcome that can only be one of two values.
- **Key Concept:**
  - Predicts the **probability** that a given input point belongs to a particular class using a logistic function (*sigmoid curve*).

---

## The Logistic Function

- **Sigmoid Function:**
  - Converts any real-valued number into a value between 0 and 1, representing probability.
  - **Equation:**  
    
    $$p(X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1X)}}$$
  - **Interpretation:**  
    - Output close to 0: Low probability of being in the positive class.
    - Output close to 1: High probability of being in the positive class.

---

## How Logistic Regression Works

- **Model Training:**
  - Fits the logistic function to the data by adjusting coefficients $\beta$ to minimize error.
- **Decision Boundary:**
  - Separates data points into different classes based on the fitted model.
  - For binary classification, it typically sets a threshold (e.g., 0.5) to classify points.
- **Log-Loss (Cross-Entropy):**
  - The loss function used to optimize the model during training, penalizing wrong classifications more heavily.

---

## Applications of Logistic Regression

- **Some Use Cases:**
  - **War or Peace:** Predicts the probability of a conflict between two countries.
  - **Male or Female:** Classifies gender (if binary).
  - **Spam or Ham:** Classifies spam emails.
  -  **Medical Diagnosis**: Predicts the presence or absence of a disease.
- **Advantages:**
  - Easy to implement and interpret (it is a parametric model - so we get coefficients!).
  - Performs well on linearly separable data.

---

## Let's predict gender (female = 0 or male = 1) from a person's height in cm...

```{r echo = FALSE, out.width='100%', fig.width = 7, fig.height=4}
data <- 
  read.csv('https://gist.githubusercontent.com/nstokoe/7d4717e96c21b8ad04ec91f361b000cb/raw/bf95a2e30fceb9f2ae990eac8379fc7d844a0196/weight-height.csv') |>
  sample_frac(1)

data$Height <- 
  data$Height * 2.54

data$Female <- 
  ifelse(data$Gender == "Male", 0, 1)

train <- 
  data[1:500,]
  
test <- 
  data[9501:10000,]

train |>
  ggplot(aes(y = Female, x = Height, colour = factor(Female))) +
  geom_jitter(height = 0, alpha = .5) +
  scale_y_continuous(breaks = c(0, .5, 1))
```

---

### 1. As seen, we can use the a linear regression to predict a binary variable (wich we treat as a continuous). 

- Our regression line for the prediction will look like this

```{r echo = FALSE, out.width='100%', fig.width = 7, fig.height=4}
train |>
  ggplot(aes(y = Female, x = Height)) +
  geom_jitter(height = 0, alpha = .5, aes(colour = factor(Female))) +
  scale_y_continuous(breaks = c(0, .5, 1)) +
  geom_smooth(method = "lm",
              se = FALSE)
```

---

```{r}
fit <- lm(Female ~ Height, data = train)
```

```{r}
pred <- predict(fit, newdata = dplyr::select(test, Female, Height))
```

```{r echo = FALSE, out.width='100%', fig.width = 7, fig.height=4}
test$pred <- pred
test |>
  ggplot(aes(y = Female, x = Height)) +
  geom_jitter(height = 0, aes(colour = pred), size = 5) +
  scale_y_continuous(breaks = c(0, .5, 1)) +
  geom_smooth(method = "lm",
              se = FALSE) +
  scale_color_distiller(palette = "RdBu")
```

---

### 2. But a different curve will probably be more appropriate to fit the data...

- Enters the sigmoid curve

```{r echo = FALSE, out.width='100%', fig.width = 7, fig.height=4}
train |>
  ggplot(aes(y = Female, x = Height)) +
  geom_jitter(height = 0, alpha = .5, aes(colour = factor(Female))) +
  scale_y_continuous(breaks = c(0, .5, 1)) +
  geom_smooth(method = "glm",
              method.args = list(family = "binomial"), 
              se = FALSE)
```

---

```{r}
fit <- glm(Female ~ Height, data = train, family = 'binomial')
```

```{r}
pred <- predict(fit, newdata = dplyr::select(test, Female, Height), 
                type = "response")
```

```{r echo = FALSE, out.width='100%', fig.width = 7, fig.height=4}
test$pred <- pred
test |>
  ggplot(aes(y = Female, x = Height)) +
  geom_jitter(height = 0, aes(colour = pred), size = 5) +
  scale_y_continuous(breaks = c(0, .5, 1)) +
  geom_smooth(method = "glm",
              method.args = list(family = "binomial"), 
              se = FALSE) +
  scale_color_distiller(palette = "RdBu", limits = c(0,1))
```

---

## How and when to use the logistic regression

- The logistic regression is a regression, so conceptually very similar to the linear regression.

- The logistic regression is parametric, so like the linear regression does provide a parameter $\beta$ (a.k.a. the coefficient) for each independent variable.

.content-box-yellow[

- Use the logistic regression instead of the linear regression when you have a **binary outcome** (i.e. dependent) **variable**.

]

---

## 1. Let's run a logistic regression to predict if an Australian voter is a female

- For the logistic regression we use the R function `glm()`, generalised linear models 

- We specify that we want a "binomial" link function, with `family = binomial`.

- We specify the `formula = y ~ x` as we do for `lm()`

```{r}
fit <- 
  glm(formula = female ~ lr + edu + equal, 
      family = binomial, # Remember to specify this
      data = aes22_recoded)
```


---

## 2. Let's summary the regression stats

.small[

```{r}
summary(fit)
```

]

---

## 3. Interpreting the results of a logistic regression

1. The interpretation of the p-value is exactly as for the linear regression.

2. The interpretation of the coefficient is also similar (if positive, positive association, etc.), yet the coefficient is not in the unit of the predictor but in log-odds: the estimate is the .content-box-purple[**log-odds change**] for each unit increase in the predictor.

   - The log-odds is **logit of the probability of the event**.  

3. We don't have an $R^2$ but an AIC (Lower AIC suggests a better model)

---

## 4. The coefficient value is not easily intepretable in relation to the unit of the variables

- We can use to predict to say something meaningful.

- What is the .content-box-red[**probability**] - not the log-odds - of a voter being a woman if ...

```{r}
pred <- 
  predict(fit, 
          newdata = data.frame(lr = 4, 
                               edu = 4,
                               equal = 5),
          type = "response") # By adding this we get the probability 
```

```{r}
pred
```


---
class: inverse, center, middle

# Individual quiz/tutorial Part 2

```{r echo = FALSE}
library(countdown)

countdown(minutes = 10, seconds = 00)
```

---
class: inverse, center, middle

# Individual in-class problem set

---
class: inverse, center, middle

# Attendance

---
class: inverse, center, middle

# See you next week Text Analysis!
