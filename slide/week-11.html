<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>SSPS [4102|6006] Data Analytics[in the Social Sciences|for Social Research]</title>
    <meta charset="utf-8" />
    <meta name="author" content="Francesco Bailo" />
    <script src="week-11_files/header-attrs/header-attrs.js"></script>
    <link href="week-11_files/remark-css/default.css" rel="stylesheet" />
    <link href="week-11_files/countdown/countdown.css" rel="stylesheet" />
    <script src="week-11_files/countdown/countdown.js"></script>
    <script src="week-11_files/htmlwidgets/htmlwidgets.js"></script>
    <script src="week-11_files/viz/viz.js"></script>
    <link href="week-11_files/DiagrammeR-styles/styles.css" rel="stylesheet" />
    <script src="week-11_files/grViz-binding/grViz.js"></script>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        TeX: { equationNumbers: { autoNumber: "AMS" } },
      });
    </script>
    <style>
    .mjx-mrow a {
      color: black;
      pointer-events: none;
      cursor: default;
    }
    </style>
    <link rel="stylesheet" href="assets/sydney-fonts.css" type="text/css" />
    <link rel="stylesheet" href="assets/sydney.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# SSPS [4102|6006] Data Analytics</br>[in the Social Sciences|for Social Research]
]
.subtitle[
## Week 11</br>Textual Data: Machine Learning Methods
]
.author[
### Francesco Bailo
]
.date[
### Semester 2, 2024 (updated: 2024-10-18)
]

---


background-image: url('assets/USydLogo.svg')
background-size: 95%

&lt;style&gt;
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
&lt;/style&gt;



---

## Acknowledgement of Country

I would like to acknowledge the Traditional Owners of Australia and recognise their continuing connection to land, water and culture. The  University of Sydney is located on the land of the Gadigal people  of the Eora Nation. I pay my respects to their Elders, past and present.
---
class: inverse, center, middle

# Please take the anonymous Week 11 Student feedback survey on Canvas!

<div class="countdown" id="timer_b75d7c49" data-update-every="1" tabindex="0" style="right:0;bottom:0;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---

## Recap from last week

- Language and Modelling
- Tokenization, Stop Words &amp; Stemming
- Sentiment analysis
- Document-Frequency Matrix
- Word Embeddings

---

## Today's class

- tidymodels for machine learning
- Regression
- Classification


---

class: inverse, center, middle

# tidymodels for machine learning

---

## What is machine learning again?

.center[&lt;img src = 'https://i.vas3k.blog/7w1.jpg' width = '100%'&gt;&lt;/img&gt;]

.footnote[Illustration from: https://vas3k.com/blog/machine_learning/]

---

## A machine learning pipline

<div id="htmlwidget-763449a5b8966efd910e" style="width:100%;height:500px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-763449a5b8966efd910e">{"x":{"diagram":"digraph {\n  # Define graph properties for a more spaced layout\n  graph [layout = dot, rankdir = TB]\n  \n  # Define nodes with increased font size\n  node [shape = ellipse, style = filled, fillcolor = lightblue, fontsize=55]\n  raw_data     [label = \"Raw Data\"]\n  train_data   [label = \"Training Data\"]\n  test_data    [label = \"Test Data\"]\n  \n  node [shape = ellipse, style = filled, fillcolor = green, fontsize=55]\n  preprocess_train [label = \"Preprocess\nTraining Data\"]\n  preprocess_test  [label = \"Preprocess\nTest Data\"]\n  \n  node [shape = ellipse, style = filled, fillcolor = orange, fontsize=55]\n  model_spec      [label = \"Model Specification\"]\n  model_training  [label = \"Model Training\"]\n  \n  node [shape = ellipse, style = filled, fillcolor = pink, fontsize=55]\n  trained_model   [label = \"Trained Model\"]\n  predict         [label = \"Predict on Test Data\"]\n  evaluate        [label = \"Evaluate Predictions\"]\n  \n  # Define edges to create space between steps\n  raw_data -> train_data [minlen=2]\n  raw_data -> test_data [minlen=2]\n  \n  train_data -> preprocess_train [minlen=2]\n  preprocess_train -> model_spec [minlen=2]\n  model_spec -> model_training [minlen=2]\n  model_training -> trained_model [minlen=2]\n  \n  test_data -> preprocess_test [minlen=2]\n  preprocess_test -> predict [minlen=2]\n  predict -> evaluate [minlen=2]\n  trained_model -> predict [minlen=2]\n  }","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>


---

## What is tidymodels?

&lt;iframe src = 'https://www.tidymodels.org/' width = '100%' height = '450px'&gt;&lt;/iframe&gt;

.footnote[https://www.tidymodels.org/]

---
## Benefit of tidymodels

- Consistent and modular framework for modelling.
- Easier to use in a pipeline format.
- Compatible with a wide range of data preprocessing and validation methods.

.center[&lt;img src = 'https://rviews.rstudio.com/post/2019-06-14-a-gentle-intro-to-tidymodels_files/figure-html/tidymodels.png' width = '100%'&gt;&lt;/img&gt;]


---

## Steps in Tidymodels 

1.  Split Data (`initial_split()`)
2.  Define Model Specification
3.  Preprocess Data with Recipe (`recipe()`)
4.  Create Workflow (`workflow()`): 2. Specification + 3. Recipe
5.  Evaluate Model Performance


---

class: inverse, center, middle

# Logistic regression

---

## 1. Loading and preparing the data


``` r
library(tidyverse)
library(tidymodels)
voting &lt;- read.csv("../data/voting.csv")
head(voting)
```

```
##   birth message voted
## 1  1981      no     0
## 2  1959      no     1
## 3  1956      no     1
## 4  1939     yes     1
## 5  1968      no     0
## 6  1967      no     0
```

Let's first recode the `voted` variable to a factor for the classification (no missing values here...)


``` r
voting &lt;- 
  voting |&gt;
  dplyr::mutate(voted = 
                  factor(case_when(voted ==  0 ~ "no", # first case
                                   voted == 1 ~ "yes"))) # second case
```

---

## 2. Splitting the data


``` r
nrow(voting)
```

```
## [1] 229444
```

``` r
set.seed(2006)
voting_split &lt;- initial_split(voting, prop = .5)
```


``` r
voting_train &lt;- training(voting_split)
nrow(voting_train)
```

```
## [1] 114722
```

``` r
voting_test &lt;- testing(voting_split)
nrow(voting_split)
```

```
## analysis 
##   114722
```


---

## Preliminary data analysis (Know Your Data!)

.pull-left[

### Our treatment variable (independent)


``` r
voting_train %&gt;% 
  ggplot(aes(x = message)) +
  geom_bar()
```

&lt;img src="week-11_files/figure-html/unnamed-chunk-7-1.svg" width="70%" style="display: block; margin: auto;" /&gt;

]



.pull-right[

### Our outcome variable (dependent)


``` r
voting_train %&gt;% 
  ggplot(aes(x = voted)) +
  geom_bar()
```

&lt;img src="week-11_files/figure-html/unnamed-chunk-8-1.svg" width="70%" style="display: block; margin: auto;" /&gt;

]

---

## Preliminary data analysis (Know Your Data!)

### Our control variable


``` r
voting_train %&gt;% 
  ggplot(aes(x = birth)) +
  geom_bar()
```

&lt;img src="week-11_files/figure-html/unnamed-chunk-9-1.svg" width="70%" style="display: block; margin: auto;" /&gt;

.center[(And this is where the boomers come from!)]

---

## 3. Define Model Specification

Now it is time to specify the model. Note that we are not using any data at this stage. Indeed, this specification can be used for different datasets.

1. We specify that we want a logistic regression, 
2. that we use the package ("engine") .content-box-purple[**glm**], which we already know, and finally  
3. that we want to do a classification (ML is either about .content-box-purple[**regression**] or .content-box-purple[**classification**])


``` r
logistic_spec &lt;- 
  logistic_reg() |&gt;
  set_engine("glm") |&gt;
  set_mode("classification")
```

---

## 4. Define Model Recipe (including our formula)

The recipe is mainly our formula and the data, both in the format we should already be familiar with


``` r
logistic_recipe &lt;- 
  recipe(voted ~ message + birth, data = voting_train)
```

(Note additional steps, such as normalisation and the creation of dummy variables are possible at this stage)


---

## 5. Create a Workflow

We add our .content-box-yellow[**Specification**] and .content-box-yellow[**Recipe**]


``` r
logistic_workflow &lt;- 
  workflow() |&gt;
  add_model(logistic_spec) |&gt;
  add_recipe(logistic_recipe)
```

## 6. Train the Model

And then we train our model (with the training data)


``` r
logistic_fit &lt;- 
  logistic_workflow |&gt;
  fit(data = voting_train)
```

---

## Check the parameters (a.k.a. estimates or coefficients) of the model

... and since this is a logistic regression you can also check the p-value.

To extract these values we can use `tidy()`.


``` r
tidy(logistic_fit)
```

```
## # A tibble: 3 × 5
##   term        estimate std.error statistic   p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)  36.8     0.882         41.7 0        
## 2 messageyes    0.367   0.0167        21.9 1.18e-106
## 3 birth        -0.0192  0.000451     -42.7 0
```

But with ML with are also interested in the **prediction**!

---

## 7. Evaluate Model Performance 

... using the .content-box-yellow[**test**] data 


``` r
logistic_predictions &lt;- 
  logistic_fit |&gt;
  predict(voting_test, type = "prob") # This will return the probabilities
head(logistic_predictions)
```

```
## # A tibble: 6 × 2
##   .pred_no .pred_yes
##      &lt;dbl&gt;     &lt;dbl&gt;
## 1    0.643     0.357
## 2    0.755     0.245
## 3    0.748     0.252
## 4    0.726     0.274
## 5    0.762     0.238
## 6    0.802     0.198
```

.content-box-green[

With a .5 threshold I will predict a 'no' to `voted` if the value of `.pred_no` is &gt;0.5.

]

---

## 7. Evaluate Model Performance 

And without `type = "prob"` we get the prediction (with a  0.5 decision treshold)


``` r
logistic_predictions &lt;- 
  logistic_fit |&gt;
  predict(voting_test) # This will return the prediction
head(logistic_predictions)
```

```
## # A tibble: 6 × 1
##   .pred_class
##   &lt;fct&gt;      
## 1 no         
## 2 no         
## 3 no         
## 4 no         
## 5 no         
## 6 no
```


---

## 7. Evaluate Model Performance

But how good is my model in predicting the actual observed value? 

I can bind the columns from the original test data and compare the actual observed value (`voted`) with the prediction.


``` r
logistic_predictions &lt;- 
  logistic_predictions |&gt;
  dplyr::bind_cols(voting_test)
head(logistic_predictions)
```

```
## # A tibble: 6 × 4
##   .pred_class birth message voted
##   &lt;fct&gt;       &lt;int&gt; &lt;chr&gt;   &lt;fct&gt;
## 1 no           1941 no      yes  
## 2 no           1969 no      no   
## 3 no           1967 no      yes  
## 4 no           1961 no      yes  
## 5 no           1971 no      yes  
## 6 no           1983 no      no
```

---

## 7. Evaluate Model Performance

Let's check how many predictions are right using `accuracy()`

- Accuracy


``` r
accuracy(logistic_predictions, truth = voted, estimate = .pred_class)
```

```
## # A tibble: 1 × 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy binary         0.687
```


And finally here is our confusion matrix (which identify a big problem!)


``` r
conf_mat(logistic_predictions, truth = voted, estimate = .pred_class)
```

```
##           Truth
## Prediction    no   yes
##        no  78545 35328
##        yes   536   313
```

---

## 7. Evaluate Model Performance

In conclusion, only knowing `message` and `birth` (age) we can predict if someone will vote or not with an accuracy of 69%. 

&gt; The model will do an OK good job in predicting the NOs but will do a terrible job in predicting the YESs.

---

class: inverse, center, middle

# Linear regression

---

### 1. Loading and preparing the data


``` r
midterms &lt;- 
  read.csv("../data/midterms.csv") |&gt;
  tidyr::drop_na() #&lt;&lt; # This will drop NAs
head(midterms)
```

```
##   year  president party approval seat.change rdi.change
## 1 1950     Truman     D       39         -29        8.2
## 2 1954 Eisenhower     R       61          -4        1.0
## 3 1958 Eisenhower     R       57         -47        1.1
## 4 1962    Kennedy     D       61          -4        5.0
## 5 1966    Johnson     D       44         -47        5.3
## 6 1970      Nixon     R       58          -8        6.6
```

### 2. Splitting the data


``` r
set.seed(2006)
midterms_split &lt;- initial_split(midterms, prop = .5)
midterms_train &lt;- training(midterms_split)
nrow(midterms_train)
```

```
## [1] 8
```

``` r
midterms_test &lt;- testing(midterms_split)
nrow(midterms_train)
```

```
## [1] 8
```

---

## 3. Define Model Specification


``` r
linear_spec &lt;- 
  linear_reg() %&gt;%
  set_engine("lm")
```

---

## 4. Define Model Recipe (including our formula)


``` r
linear_recipe &lt;- 
  recipe(seat.change ~ approval + rdi.change, data = midterms_train)
```


---

## 5. Create a Workflow ...


``` r
linear_workflow &lt;- 
  workflow() |&gt;
  add_model(linear_spec) |&gt;
  add_recipe(linear_recipe)
```

## 6. ... and fit the model


``` r
linear_fit &lt;- 
  linear_workflow |&gt;
  fit(data = midterms_train)
```

---

## Check the parameters


``` r
tidy(linear_fit)
```

```
## # A tibble: 3 × 5
##   term        estimate std.error statistic p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept)  -112.      37.2      -3.02   0.0295
## 2 approval        1.67     0.554     3.02   0.0294
## 3 rdi.change      1.72     2.64      0.650  0.544
```

---

## 7. Evaluate Model Performance... on train data


``` r
linear_predictions &lt;- 
  linear_fit |&gt;
  predict(midterms_train) |&gt;
  dplyr::bind_cols(midterms_train)
head(linear_predictions)
```

```
## # A tibble: 6 × 7
##    .pred  year president  party approval seat.change rdi.change
##    &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;      &lt;chr&gt;    &lt;int&gt;       &lt;int&gt;      &lt;dbl&gt;
## 1  -3.81  1970 Nixon      R           58          -8        6.6
## 2 -28.5   1994 Clinton    D           46         -53        3.9
## 3 -33.7   1982 Reagan     R           42         -28        4.8
## 4  -8.41  1954 Eisenhower R           61          -4        1  
## 5  -1.54  1962 Kennedy    D           61          -4        5  
## 6  -2.32  2002 W. Bush    R           63           6        2.6
```

---

## What is `\(R^2\)` again?

- `\(R^2\)`, or the **coefficient of determination**, is a statistical metric used to evaluate the performance of a regression model.
- It indicates the proportion of the variance in the dependent variable that is predictable from the independent variables.

`$$R^2 = 1 - \frac{\text{SS}_{\text{res}}}{\text{SS}_{\text{tot}}}$$`

where:
- `\(\text{SS}_{\text{res}}\)`: Sum of squared residuals (unexplained variance)
- `\(\text{SS}_{\text{tot}}\)`: Total sum of squares (total variance in the outcome)

---

## Interpretation of `\(R^2\)`

- **$R^2 = 1$**: Perfect fit. The model explains all variability in the data.
- **$R^2 = 0$**: No fit. The model explains none of the variability.
- **Between 0 and 1**: Partially explains the variance.
    - For example, `\(R^2 = 0.75\)` implies that 75% of the variability in the outcome is explained by the model.

## Limitations
- Adding more variables can increase `\(R^2\)`, even if they don’t improve the model significantly. Adjusted `\(R^2\)` can help address this issue.

---

## What is the `\(R^2\)` on our fit?

Use the `rsq_trad` function to find it: where `truth`, or the ground truth value is the observed value and `estimate` is your prediction.


``` r
rsq_trad(linear_predictions, truth = seat.change, estimate = .pred)
```

```
## # A tibble: 1 × 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 rsq_trad standard       0.685
```

---

## What is RMSE?

- **Root Mean Square Error (RMSE)** is a metric that measures the average magnitude of the errors in predictions made by a regression model.

- It represents the square root of the average of squared differences between predicted and actual values.

`$$\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$$`

where:
- `\(n\)`: Number of observations
- `\(y_i\)`: Actual value of the outcome for observation `\(i\)`
- `\(\hat{y}_i\)`: Predicted value of the outcome for observation `\(i\)`

---

## Interpretation

- RMSE is always non-negative, with lower values indicating a better fit.
- An RMSE of 0 means perfect prediction accuracy.
- **Units**: RMSE is in the same units as the dependent variable, making it interpretable in the context of the data.

## Limitations
- RMSE is sensitive to outliers since errors are squared.
- It doesn’t provide an interpretation for how large or small the error is in relative terms; comparing RMSE across different datasets or contexts may require normalization.

---

## What is RMSE on our fit?


``` r
rmse(linear_predictions, truth = seat.change, estimate = .pred)
```

```
## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard        10.2
```

Use the `rmse` function to find it: where `truth`, or the ground truth value is the observed value and `estimate` is your prediction.

---

## Importance of Evaluation Metrics in Machine Learning

### Why Evaluation Metrics Matter

.small[

- **Assess Model Performance**: Metrics like accuracy, RMSE, and `\(R^2\)` help quantify how well a model predicts outcomes, guiding improvements.

- **Compare Models**: Metrics allow us to objectively compare different models to find the best fit for the problem.

- **Understand Errors**: By analyzing metrics such as precision, recall, or RMSE, we understand where a model may mispredict, enabling targeted refinements.

- **Avoid Overfitting/Underfitting**: Metrics reveal if a model generalizes well to new data, helping avoid models that only perform well on the training set.

- **Select Relevant Metrics**: Choosing the right metric aligns with the specific goals of a task (e.g., accuracy for classification, RMSE for regression), optimizing model impact.

]

---

## 7. Evaluate Model Performance... on test data!


``` r
linear_predictions &lt;- 
  linear_fit |&gt;
  predict(midterms_test) |&gt;
  dplyr::bind_cols(midterms_test)
```


``` r
ggplot(linear_predictions) +
  geom_point(aes(x = seat.change, y = .pred)) +
  geom_abline() +
  lims(x = c(-63,63), y = c(-63,63))
```

&lt;img src="week-11_files/figure-html/unnamed-chunk-31-1.svg" width="30%" style="display: block; margin: auto;" /&gt;

---
class: inverse, center, middle

# Text analysis: Regression

---

- We now turn to using text analysis and machine learning to predict some value based on the features we extract from some text.

## Let's go back to the debate transcripts we used last week


---

## 1. Load and prepare data

... Since text analysis is computationally intense we also reduce the size of the data


``` r
load("../data/debate_transcripts.rda")

## Let's reduce the data set size
debate_transcripts &lt;-
  debate_transcripts |&gt;
  dplyr::sample_n(1000)
```


---

## Know your data


``` r
debate_transcripts |&gt;
  dplyr::count(election_year) |&gt;
  ggplot(aes(election_year, n)) + 
  geom_col() + labs(x = "year", y = "Number of speeches per year")
```

&lt;img src="week-11_files/figure-html/unnamed-chunk-33-1.svg" width="30%" style="display: block; margin: auto;" /&gt;

---

## 2. Splitting the data


``` r
debate_split &lt;- initial_split(debate_transcripts)

debate_train &lt;- training(debate_split) 
nrow(debate_train)
```

```
## [1] 750
```

``` r
debate_test &lt;- testing(debate_split)
nrow(debate_test)
```

```
## [1] 250
```

---

## 4. Define Model Specification

... This is exactly as before


``` r
linear_spec &lt;- 
  linear_reg() |&gt;
  set_engine("lm") |&gt;
  set_mode("regression")
```

---

## 4. Define Model Recipe (including our formula)

This part is sligthly different because we extract features from text!

- We use the same text processing steps see last week 

- We use the textrecipes package to do it within the tidymodels framework

- Note that you can combine text features and other features in your model (e.g., date of debate)


``` r
# install.packages('textrecipes')
library(textrecipes)

debate_recipe &lt;- 
  recipe(election_year ~ text, data = debate_train) |&gt; 
  step_tokenize(text) |&gt;
  step_tokenfilter(text, max_tokens = 1000) |&gt;
  step_tfidf(text) |&gt;
  step_normalize(all_predictors())
```

---

## 5. Create a Workflow ...


``` r
linear_workflow &lt;- 
  workflow() |&gt;
  add_model(linear_spec) |&gt;
  add_recipe(debate_recipe)
```


## 6. ... and fit the model


``` r
linear_fit &lt;- 
  linear_workflow |&gt;
  fit(data = debate_train)
```

---

## Let's Explore the results

### What are the tokens that predict more recent years (remember formula `election_year ~ text`)


``` r
tidy(linear_fit) |&gt;
  dplyr::arrange(-estimate)
```

```
## # A tibble: 1,001 × 5
##    term                     estimate std.error statistic   p.value
##    &lt;chr&gt;                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
##  1 (Intercept)                 2012.     0.283  7119.    5.99e-163
##  2 tfidf_text_congresswoman     431.   763.        0.566 5.74e-  1
##  3 tfidf_text_commander         426.   455.        0.936 3.53e-  1
##  4 tfidf_text_black             282.   351.        0.804 4.25e-  1
##  5 tfidf_text_income            274.   379.        0.722 4.74e-  1
##  6 tfidf_text_affairs           258.   292.        0.885 3.80e-  1
##  7 tfidf_text_east              251.   270.        0.930 3.57e-  1
##  8 tfidf_text_bin               192.   251.        0.766 4.47e-  1
##  9 tfidf_text_6                 177.   228.        0.776 4.41e-  1
## 10 tfidf_text_fence             167.   304.        0.550 5.84e-  1
## # ℹ 991 more rows
```

---

### And What are the tokens that predict further in the past (remember formula `election_year ~ text`)


``` r
## Further in the past
tidy(linear_fit) |&gt;
  arrange(estimate)
```

```
## # A tibble: 1,001 × 5
##    term                estimate std.error statistic p.value
##    &lt;chr&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
##  1 tfidf_text_bachmann    -435.      770.    -0.566   0.574
##  2 tfidf_text_billion     -349.      372.    -0.938   0.352
##  3 tfidf_text_higher      -305.      425.    -0.717   0.476
##  4 tfidf_text_middle      -302.      338.    -0.895   0.375
##  5 tfidf_text_chief       -300.      277.    -1.08    0.283
##  6 tfidf_text_defense     -265.      334.    -0.792   0.432
##  7 tfidf_text_havent      -177.      218.    -0.813   0.420
##  8 tfidf_text_hunting     -161.      233.    -0.694   0.491
##  9 tfidf_text_hope        -151.      169.    -0.894   0.375
## 10 tfidf_text_oil         -150.      363.    -0.413   0.681
## # ℹ 991 more rows
```

---

## 7. Evaluate Model Performance... on train data


``` r
linear_predictions &lt;- 
  linear_fit |&gt;
  predict(debate_train) |&gt;
  dplyr::bind_cols(debate_train)
```

---

## `\(R^2\)`


``` r
rsq_trad(linear_predictions, truth = election_year, estimate = .pred)
```

```
## # A tibble: 1 × 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 rsq_trad standard       0.966
```

## `\(RMSE\)`


``` r
rmse(linear_predictions, truth = election_year, estimate = .pred)
```

```
## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard        2.08
```


---

## Can we do better? 

- Machine learning is all about fine-tuning your workflow to improve the model.

- That's why is important to fine tune it on the train set!

### We could try to remove stopwords and see if the prediction improves!

---

## With tidymodels, I don't need to redefine everything.

- I only need to interve on the step that I want to change...

---

## 4. Define Model Recipe (including our formula)


``` r
debate_recipe &lt;- 
  recipe(election_year ~ text, data = debate_train) |&gt; 
  step_tokenize(text) |&gt;
  step_stopwords() |&gt; #&lt;&lt; # Removed the stop words
  step_tokenfilter(text, max_tokens = 1000) |&gt;
  step_tf(text) |&gt; #&lt;&lt; # Change tf
  step_normalize(all_predictors())
```

---

## 5. Re-Create a Workflow ...

... with new `debate_recipe`


``` r
linear_workflow &lt;- 
  workflow() |&gt;
  add_model(linear_spec) |&gt;
  add_recipe(debate_recipe)
```


## 6. ... and fit the model


``` r
linear_fit &lt;- 
  linear_workflow |&gt;
  fit(data = debate_train)
```

---

## 7. Now we compare the new evaluation metrics with the old


``` r
linear_predictions &lt;- 
  linear_fit |&gt;
  predict(debate_train) |&gt;
  dplyr::bind_cols(debate_train)
```


``` r
rsq_trad(linear_predictions, truth = election_year, estimate = .pred)
```

```
## # A tibble: 1 × 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 rsq_trad standard       0.342
```


``` r
rmse(linear_predictions, truth = election_year, estimate = .pred)
```

```
## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard        9.14
```



---
class: inverse, center, middle

# Text analysis: Classification

---

## 1. Load and prepare data

... We have already loaded the data. Let's only focus on classifying two speakers...


``` r
debate_clinton_trump &lt;-
  debate_transcripts |&gt;
  dplyr::filter(speaker %in% 
                  c("Hillary Clinton", "Donald Trump")) |&gt;
  dplyr::mutate(speaker = factor(speaker))
```

---

## 2. Splitting the data


``` r
debate_split &lt;- initial_split(debate_clinton_trump, prop = 1/2)  
debate_train &lt;- training(debate_split) 
nrow(debate_train)
```

```
## [1] 37
```

``` r
debate_test &lt;- testing(debate_split)
nrow(debate_test)
```

```
## [1] 37
```

---

## 3. Define Model Specification for text


``` r
debate_recipe &lt;- 
  recipe(speaker ~ text, data = debate_train) %&gt;% 
  step_tokenize(text) %&gt;% 
  step_tokenfilter(text, max_tokens = 1000) %&gt;% 
  step_tfidf(text) %&gt;% 
  step_normalize(all_predictors())
```

## 4. Define Model Recipe (including our formula)


``` r
logistic_spec &lt;- 
  logistic_reg() |&gt;
  set_engine("glm") |&gt;
  set_mode("classification")
```

---

## 5. Create a Workflow ...


``` r
logistic_workflow &lt;- 
  workflow() |&gt;
  add_model(logistic_spec) |&gt;
  add_recipe(debate_recipe)
```

## 6. ... and fit the model


``` r
logistic_fit &lt;- 
  logistic_workflow |&gt;
  fit(data = debate_train)
```

---

## Let's explore the results on our test data!


``` r
logistic_predictions &lt;- 
  logistic_fit |&gt;
  predict(debate_test) |&gt;
  dplyr::bind_cols(debate_test)
logistic_predictions
```

```
## # A tibble: 37 × 7
##    .pred_class     speaker        text  type  election_year date       candidate
##    &lt;fct&gt;           &lt;fct&gt;          &lt;chr&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;date&gt;         &lt;dbl&gt;
##  1 Donald Trump    Hillary Clint… "Wel… Pres           2016 2016-10-19         1
##  2 Donald Trump    Donald Trump   "Fir… Pres           2016 2016-09-26         1
##  3 Donald Trump    Hillary Clint… "Dem… Dem            2016 2015-10-13         1
##  4 Donald Trump    Donald Trump   "Wel… Pres           2020 2020-09-29         1
##  5 Donald Trump    Donald Trump   "I d… Rep            2016 2015-09-16         1
##  6 Donald Trump    Hillary Clint… "… t… Pres           2016 2016-10-19         1
##  7 Donald Trump    Hillary Clint… "Wel… Dem            2016 2015-10-13         1
##  8 Donald Trump    Hillary Clint… "Wel… Pres           2016 2016-10-19         1
##  9 Donald Trump    Donald Trump   "I t… Rep            2016 2016-12-15         1
## 10 Hillary Clinton Donald Trump   "And… Pres           2016 2016-10-09         1
## # ℹ 27 more rows
```

---

## 7. Evaluate the model on test data

- Accuracy


``` r
accuracy(logistic_predictions, truth = speaker, estimate = .pred_class)
```

```
## # A tibble: 1 × 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy binary         0.622
```

- And confusion matrix


``` r
conf_mat(logistic_predictions, truth = speaker, estimate = .pred_class)
```

```
##                  Truth
## Prediction        Donald Trump Hillary Clinton
##   Donald Trump              23              12
##   Hillary Clinton            2               0
```




---
class: inverse, center, middle

# Individual quiz/tutorial Part 2

<div class="countdown" id="timer_affc2168" data-update-every="1" tabindex="0" style="right:0;bottom:0;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
class: inverse, center, middle

# Individual on A3 with peer-review

<div class="countdown" id="timer_8694b523" data-update-every="1" tabindex="0" style="right:0;bottom:0;">
<div class="countdown-controls"><button class="countdown-bump-down">&minus;</button><button class="countdown-bump-up">&plus;</button></div>
<code class="countdown-time"><span class="countdown-digits minutes">30</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---
class: inverse, center, middle

# Individual problem set


---
class: inverse, center, middle

# Attendance

---
class: inverse, center, middle

# See you next week for Network and Spatial Data!


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="assets/remark-zoom.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "4:3",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
