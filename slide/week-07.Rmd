---
title: "SSPS [4102|6006] Data Analytics</br>[in the Social Sciences|for Social Research]"
subtitle: "Week 07</br>Probability"
author: "Francesco Bailo"
date: "Semester 2, 2024 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    css: ["default", "assets/sydney-fonts.css", "assets/sydney.css"]
    self_contained: false # if true, fonts will be stored locally
    seal: true # show a title slide with YAML information
    includes:
      in_header: "assets/mathjax-equation-numbers.html"
    nature:
      beforeInit: ["assets/remark-zoom.js", "https://platform.twitter.com/widgets.js"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '4:3' # alternatives '16:9' or '4:3' or others e.g. 13:9
      navigation:
        scroll: false # disable slide transitions by scrolling

---

background-image: url('assets/USydLogo.svg')
background-size: 95%

<style>
pre {
  overflow-x: auto;
}
pre code {
  word-wrap: normal;
  white-space: pre;
}
</style>

```{r setup, include=FALSE}

options(htmltools.dir.version = FALSE)

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
                      dev = 'svg', 
                      fig.width = 4, 
                      fig.height = 4, out.width="30%",
                      fig.align="center")

library(knitr)
library(kableExtra)
library(tidyverse)
library(sf)
library(DiagrammeR)
library(cowplot)
library(gapminder)

ggplot2::theme_set(theme_bw())

```

---

## Acknowledgement of Country

I would like to acknowledge the Traditional Owners of Australia and recognise their continuing connection to land, water and culture. The  University of Sydney is located on the land of the Gadigal people  of the Eora Nation. I pay my respects to their Elders, past and present.

---

## Recap from last week

- `lm()` with one independent variable.
- $R^2$, a model fit measure, which represents the proportion of variability in $Y$ (outcome or dependent variable) that is explained by a linear combination of $X$ (predictors or independent variables).  

---

## Today's class

| Time        | Content                                       |
|-------------|-----------------------------------------------|
| 11:00-11:30 | Lab: Multiple regression models and predict() |
| 11:30-11:40 | Individual quiz/tutorial Part 1               |
| 11:40-12:30 | Probability                                   |
| 12:30-12:45 | Break                                         |
| 12:45-13:00 | Individual quiz/tutorial Part 1               |
| 13:00-14:00 | Group in-class problem set                    |


---

## Housekeeping: Free Access to Data Camp courses, tracks and projects

- This is totally optional, and you should consider it if you want to put some extra time in developing your R skills

- Access Data Camp classroom [here](https://www.datacamp.com/groups/shared_links/3ffac39d779d15680cd302d21bd72ca5fb49857b85e87494a2c3ed8f2438642b) (create account using your USYD email)

- You should be able to access tracks, courses, and projects I have assigned to the team

- This is very much experimental, feedback on this very much appreciated!

.center[<img src = 'https://lts.lehigh.edu/sites/default/files/field/image/DataCamp%20for%20LTS%20News.png' width = '50%'>]



---
class: inverse, center, middle

# Before talking about probability, let's go back a bit and talk about multiple regression models ...

---

## Modelling relationships between variables

- A causal graphical model represent graphically variables and the vectors of causality that connect them (what causes what). 

- Each node is a random variable.

```{r echo = FALSE, out.width = "100%"}
library(DiagrammeR)

# Create a DAG using DiagrammeR
dag <- grViz("
  digraph DAG {
    graph [rankdir = LR]

    # Nodes
    A [label = 'Parent A']
    B [label = 'Parent B']
    C [label = 'Child C']

    # Edges
    A -> C
    B -> C
  }
")

# Render the DAG
dag
```


---

### NOW, using Padlet let's brainstorm a graphical model trying to address (also in terms of measurability) the BIG question of political science as of 2024. 

--

### Will Taylor Swiftâ€™s Endorsement Affect the US Election? A Causal Graphical Model

.center[

<img src = '../img/padlet_week_07.png' width = '25%'>

OR 

[click here or in Canvas](https://sydney.padlet.org/francescobailo/will-taylor-swift-s-endorsement-affect-the-us-election-a-cau-41qsn1lh63sz1fl6) 


]




---

## Multiple Linear Regression Models

Linear models with more than one $X$ variable

$$\widehat{Y}_i = \widehat{\alpha} + \widehat{\beta}_1 X_{i1}+... + \widehat{\beta}_p X_{ip}$$

where:

- $\widehat{Y_i}$ is the predicted value of $Y$ for observation $i$

- $\widehat{\alpha}$ is the estimated intercept coefficient  

 each $\widehat{\beta}_j$ (pronounced beta hat sub j) is the estimated coefficient for variable $X_j$ ( $j{=} {1}, ..., p$ ) - we use $j$ as a stand-in for all different subscripts.

- each $X_{ij}$ is the observed value of the variable $X_j$ for observation $i$ ( $j{=} {1}, ..., p$ )

- $p$ is the total number of $X$ variables in the model.

.footnote[Slide adapted from slides by Prof. Llaudet]


---

## Simple vs Multiple regression

.pull-left[

| simple regression                          |
|--------------------------------------------|
| $\widehat{Y} = \widehat{\alpha} + \widehat{\beta} X$  |
| $\widehat{\alpha}$: $\widehat{Y}$ when $X=0$ |
| $\widehat{\beta}$: $\triangle\widehat{Y}$ associated with $\triangle X=1$ |


]

.pull-right[

| multiple regression                                                             |
|---------------------------------------------------------------------------------|
| $\widehat{Y} = \widehat{\alpha} + \widehat{\beta}_{1} X_{1} + ... + \widehat{\beta}_p X_{p}$  |
| $\widehat{\alpha}$: $\widehat{Y}$ when all $X_j=0$ ( $j=1,...,p$ ) |
| each $\widehat{\beta}_j$: $\triangle\widehat{Y}$ associated with $\triangle X_j=1$, while holding all other $X$ variables constant or *ceteris paribus* |


]

.footnote[Slide adapted from slides by Prof. Llaudet]

---

## Interpretation of Coefficients in Multiple Linear Regression Models

$$\widehat{Y} = \widehat{\alpha} + \widehat{\beta}_{1} X_{1} + ... + \widehat{\beta}_p X_{p}$$

- $\widehat{\alpha}$ is the $\widehat{Y}$ when *all* $X_j{=}{0}$

- Because there are multiple $X$ variables, there are multiple $\widehat{\beta}$ coefficients (one for each $X$ variable)

.content-box-yellow[

- Each $\widehat{\beta}_j$ is the $\triangle \widehat{Y}$ associated with $\triangle X_j$=1, *while holding all other $X$ variables constant* 

]

.footnote[Slide adapted from slides by Prof. Llaudet]
---
class: inverse, center, middle

# Lab: lm() with multiple regression

---

## US midterm elections data<sup>1</sup>

| Variable name | Description |
| ------------- | ----------- |
| `year` | midterm election year |
| `president` | name of president |
| `party` | Democrat or Republican |
| `approval` | Gallup approval rating at midterms |
| `seat.change` | change in the number of House seat's for the president's party |
| `rdi.change` | change in real disposable income over the year before |

---

## Scenario

Imagine we are in 2018 just *before* the US mid-term election. So for the 2018 observation,

- .content-box-green[`president`] is known (Trump);
- .content-box-green[`party`] is known (Republican);
- .content-box-green[`approval`] is known;
- .content-box-green[`rdi.change`] is known; but
- .content-box-red[`seat.change`] is **unknown**, since it is about a **future** event... Yet we could predict it :-)


.footnote[[1] Slides adapted from http://www.mattblackwell.org/files/teaching/gov50/regression-ii.pdf]


---

```{r echo = F}
midterms <- read.csv("../data/midterms.csv")
```

```{r eval = F}
midterms <- read.csv("midterms.csv")
```

The top of the table...

```{r echo = F}
midterms %>%
  slice(1:5) %>%
  kable()
```

... and the bottom of the table.

```{r echo = F}
midterms %>%
  slice(17:19) %>%
  kable()
```

---

## Simple regression

$$ \widehat{seat.change} = \hat{\alpha} + \hat{\beta} \times approval $$

```{r}
fit_simple <- 
  lm(formula = seat.change ~ approval, 
     data = midterms)
```

.content-box-yellow[

Remember: the attribute `formula` is constructed as `outcome ~ predictor`.

]

--

### How do you geta summary of the results from `lm()`?

- For example, you can use `summary()` (but there are many other functions you could use...)

---

```{r}
summary(fit_simple)
```

--
.small[
So far, we discussed .content-box-yellow["Estimate"], which is the coefficient for each independent variable ( $\hat{\beta}_j$) and the intercept ( $\hat{\alpha}$ ) and the .content-box-yellow["Multiple R-squared"], which is the proportion of the variation in $Y$ explained by the model.
]
---

## Mutliple regression

Using the `formula` syntax `outcome ~ predictor_1 + predictor_2 + ...` we can add additional predictors (i.e independent variables).

```{r}
fit_multi <- 
  lm(formula = seat.change ~ approval + rdi.change, 
     data = midterms)
```

---

<div style = 'font-size: 14pt'>

```{r}
summary(fit_multi)
```

</div>
The only difference here is that we have an extra row for the additional predictors. The interpretation of the .content-box-yellow["Estimate"] now is variation in $\hat{Y}$ ( i.e. $\Delta\hat{Y}$ ) when variation in $X_j$ is 1 ( i.e. $\Delta X_j=1$ ) and when other variables are held constant.

---

## Using predict()

If we don't pass new data, the function `predict()` will just return the prediction for $Y$ (i.e. $\hat{Y}$ ) for each observation in our original data.

```{r}
predict(fit_multi)
```

.small[
The number you see above the prediction is the row number of your `midterms` data (which is replaced by labels if your rows are named). Note that the first and last rows are (of course!) missing because the `seat.change` is missing.
]

```{r}
midterms[1,]
```

---

## Predict based on your data

But we don't need to use the original data for our predictions. Remember that `lm()` gives us a continuous straight line; we can predict $Y$ for any value of each $X_j$. 

For example, let's get $\widehat{seat.change}$ using our simple model for an approval rate of 20% and 80% (which is not in the original data set).

```{r}
my_new_data <- #<<
  data.frame(approval = c(20, 80)) # Create new data #<<

predict(fit_simple, 
        newdata = my_new_data) # Pass the new data to predict() #<< 
```

With an approval rate of .content-box-green[**20**] the president's party is predicted to lose .content-box-purple[**68**] seats and with an approval rate of .content-box-green[**80**] to gain .content-box-purple[**17**] seats.

---

## How confident are we in our prediction?

To obtain the 95% confidence intervals (more on this next week) around our predicted values ( $\hat{Y}$ ), we can add `interval = "confidence"`.

```{r}
seat.change_prediction <- # Storing prediction #<< 
  predict(fit_simple, 
          newdata = my_new_data, 
          interval = "confidence") # Adding confidence interval #<<
seat.change_prediction 
```

---

# Which we can then plot... 

```{r out.width = "30%"}
# First we need to create a data.frame adding the `approval` rate
# that we want to use as input values
data.frame(seat.change_prediction,
           approval = c(20, 80)) |>
# Then we plot  
  ggplot(aes(y = fit, 
             ymin = lwr, ymax = upr, 
             x = approval)) +
  geom_point() +
  geom_errorbar() +
  labs(y = "seat.change")
```

---

## Let's compare our predictions with the actual results ... 

- We are in 2018, just before the mid-term. (Trump is president).

- We want to use `approval` to predict the outcome of the upcoming midterm election for Trump's party (i.e., $\widehat{seat.change}$). 

- Note that the 2018-Trump row was not used to estimate the model because of the missing value (of course, we are before the mid-term).

- We only know that Trump's approval rate in 2018 was .content-box-green[**38%**]. So we can plug that value in...

--

```{r}
predict(fit_simple, newdata = data.frame(approval = 38))
```

We predict that in the 2018 mid-term his party will lose about .content-box-purple[**43**] seats.

---

## Does adding predictors improve the accuracy of our model?

This is out multivariate regression model: in addition to `approval` we are also using `rdi.change` (change in real disposable income over the year before, an economic measure)

```{r}
fit_multi <- 
  lm(formula = seat.change ~ approval + rdi.change, 
     data = midterms)
```


```{r}
fit_multi
```

---

## Now, let's predict using our fit_multi...

```{r}
predict(fit_multi, 
        newdata = data.frame(approval = 38,
                             rdi.change = 4.1)) # Observed value #<<
```

Using the multiple regression model, we predict his party will lose .content-box-purple[**47**] seats instead of about .content-box-purple[**43**] seats with the simple regression model.

## Which model did better?

### Let's check Wikipedia!

---

<iframe id="wiki" src="https://en.wikipedia.org/wiki/2018_United_States_elections" width = '900px' height = '600px'></iframe>

---

.content-box-yellow[

Adding extra an variable in this case **decreased** the accuracy of the model!

]

.content-box-red[

The substantial interpretation here is that the national economy does not explain voting behaviour as much as we think...

]



### How could we have known better?

We could have checked the .content-box-yellow[**"Adjusted R-squared"**] of the two models...

The .content-box-yellow[**""Multiple R-squared"**], the $R^2$ we saw last week, explains the variation in the outcome variable that is explained by the predictors. Yet, the multiple R-squared will **always** increase if we add new predictors. So it is useless to compare models after adding an extra predictors...

This is why it is more appropriate to compare the .content-box-yellow[**"Adjusted R-squared"**] when we add new predictors. 

---

```{r}
summary(fit_simple)
```

---

```{r}
summary(fit_multi)
```

---
class: inverse, center, middle

# Individual in-class quiz/tutorial (Part 1, until `predict()` included)

```{r echo = FALSE}
library(countdown)

countdown(minutes = 10, seconds = 00)
```

---
class: inverse, center, middle


Prof. Llaudet slides on Probability


---
class: inverse, center, middle

# Individual in-class quiz/tutorial (Part 2)

```{r echo = FALSE}
library(countdown)

countdown(minutes = 10, seconds = 00)
```

---
class: inverse, center, middle

# Group in-class problem set

---
class: inverse, center, middle

# Attendance

---
class: inverse, center, middle

# See you next week with Uncertainty (and p-values)!

